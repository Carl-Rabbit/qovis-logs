Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
23/11/10 17:21:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Spark context Web UI available at http://Jiahao:4040
Spark context available as 'sc' (master = local[*], app id = local-1699608073397).
Spark session available as 'spark'.
23/11/10 17:21:15 DEBUG FileSystem: Looking for FS supporting file
23/11/10 17:21:15 DEBUG FileSystem: looking for configuration option fs.file.impl
23/11/10 17:21:15 DEBUG FileSystem: Looking in service filesystems for implementation class
23/11/10 17:21:15 DEBUG FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
23/11/10 17:21:15 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
23/11/10 17:21:15 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.eventLog.enabled -> true
23/11/10 17:21:15 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.jars -> 
23/11/10 17:21:15 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.repl.class.outputDir -> /tmp/spark-5ab950c8-dfa4-414c-b15f-638019ca15e5/repl-f1a650ef-e549-438e-8b3e-a590117a8263
23/11/10 17:21:15 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.app.name -> Spark shell
23/11/10 17:21:15 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.submit.pyFiles -> 
23/11/10 17:21:15 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.ui.showConsoleProgress -> true
23/11/10 17:21:15 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.app.submitTime -> 1699608070280
23/11/10 17:21:15 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.sql.cbo.enabled -> true
23/11/10 17:21:15 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.submit.deployMode -> client
23/11/10 17:21:15 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.master -> local[*]
23/11/10 17:21:15 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.sql.statistics.histogram.enabled -> true
23/11/10 17:21:15 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.home -> /home/dbgroup/Applications/spark-3.3.0
23/11/10 17:21:15 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.eventLog.dir -> hdfs://Jiahao:9000/spark3.3.0-logs
23/11/10 17:21:15 DEBUG SharedState: Applying static initial session options to SparkConf: spark.sql.catalogImplementation -> hive
23/11/10 17:21:15 INFO SharedState: Warehouse path is 'hdfs://Jiahao:9000/warehouse'.
23/11/10 17:21:15 DEBUG FsUrlStreamHandlerFactory: Creating handler for protocol jar
23/11/10 17:21:15 DEBUG FileSystem: Looking for FS supporting jar
23/11/10 17:21:15 DEBUG FileSystem: looking for configuration option fs.jar.impl
23/11/10 17:21:15 DEBUG FileSystem: Looking in service filesystems for implementation class
23/11/10 17:21:15 DEBUG FsUrlStreamHandlerFactory: Unknown protocol jar, delegating to default implementation
23/11/10 17:21:15 DEBUG FsUrlStreamHandlerFactory: Creating handler for protocol file
23/11/10 17:21:15 DEBUG FileSystem: Looking for FS supporting file
23/11/10 17:21:15 DEBUG FileSystem: looking for configuration option fs.file.impl
23/11/10 17:21:15 DEBUG FileSystem: Looking in service filesystems for implementation class
23/11/10 17:21:15 DEBUG FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
23/11/10 17:21:15 DEBUG FsUrlStreamHandlerFactory: Found implementation of file: class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
23/11/10 17:21:15 DEBUG FsUrlStreamHandlerFactory: Using handler for protocol file
23/11/10 17:21:16 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.expressions.codegen.package$ExpressionCanonicalizer$CleanExpressions ===
!input[0, int, false] AS value#0   input[0, int, false]
!+- input[0, int, false]           
           
23/11/10 17:21:16 TRACE package$ExpressionCanonicalizer: Fixed point reached for batch CleanExpressions after 2 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: 
=== Result of Batch CleanExpressions ===
!input[0, int, false] AS value#0   input[0, int, false]
!+- input[0, int, false]           
          
23/11/10 17:21:16 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 2
Total time: 0.001125798 seconds
Total number of effective runs: 1
Total time of effective runs: 9.3794E-4 seconds
      
23/11/10 17:21:16 DEBUG GenerateUnsafeProjection: code for input[0, int, false]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */     int value_0 = i.getInt(0);
/* 032 */     mutableStateArray_0[0].write(0, value_0);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

23/11/10 17:21:16 DEBUG CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */     int value_0 = i.getInt(0);
/* 032 */     mutableStateArray_0[0].write(0, value_0);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

23/11/10 17:21:16 INFO CodeGenerator: Code generated in 122.755339 ms
23/11/10 17:21:16 DEBUG CatalystSqlParser: Parsing command: spark_grouping_id
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Substitution after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Substitution has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Disable Hints after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Disable Hints has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Hints after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Hints has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Simple Sanity Check after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Simple Sanity Check has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Keep Legacy Outputs after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Keep Legacy Outputs has no effect.
23/11/10 17:21:16 TRACE Analyzer$ResolveReferences: Attempting to resolve LocalRelation [value#1]
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Resolution after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Resolution has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove TempResolvedColumn after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Remove TempResolvedColumn has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Apply Char Padding after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Apply Char Padding has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Post-Hoc Resolution after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Post-Hoc Resolution has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove Unresolved Hints after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Remove Unresolved Hints has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Nondeterministic after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Nondeterministic has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UDF after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch UDF has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UpdateNullability after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch UpdateNullability has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Subquery after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Subquery has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Cleanup after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Cleanup has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch HandleAnalysisOnlyCommand after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch HandleAnalysisOnlyCommand has no effect.
23/11/10 17:21:16 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 81
Total time: 0.087054389 seconds
Total number of effective runs: 0
Total time of effective runs: 0.0 seconds
      
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Substitution after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Substitution has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Disable Hints after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Disable Hints has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Hints after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Hints has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Simple Sanity Check after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Simple Sanity Check has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Keep Legacy Outputs after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Keep Legacy Outputs has no effect.
23/11/10 17:21:16 TRACE Analyzer$ResolveReferences: Attempting to resolve LocalRelation <empty>, [value#1]
23/11/10 17:21:16 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveDeserializer ===
!'DeserializeToObject unresolveddeserializer(assertnotnull(upcast(getcolumnbyordinal(0, IntegerType), IntegerType, - root class: "scala.Int"))), obj#2: int   'DeserializeToObject assertnotnull(upcast(value#1, IntegerType, - root class: "scala.Int")), obj#2: int
 +- LocalRelation <empty>, [value#1]                                                                                                                          +- LocalRelation <empty>, [value#1]
           
23/11/10 17:21:16 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveUpCast ===
!'DeserializeToObject assertnotnull(upcast(value#1, IntegerType, - root class: "scala.Int")), obj#2: int   DeserializeToObject assertnotnull(cast(value#1 as int)), obj#2: int
 +- LocalRelation <empty>, [value#1]                                                                       +- LocalRelation <empty>, [value#1]
           
23/11/10 17:21:16 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.analysis.ResolveTimeZone ===
 DeserializeToObject assertnotnull(cast(value#1 as int)), obj#2: int   DeserializeToObject assertnotnull(cast(value#1 as int)), obj#2: int
 +- LocalRelation <empty>, [value#1]                                   +- LocalRelation <empty>, [value#1]
           
23/11/10 17:21:16 TRACE Analyzer$ResolveReferences: Attempting to resolve DeserializeToObject assertnotnull(cast(value#1 as int)), obj#2: int
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Resolution after 2 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(assertnotnull(upcast(getcolumnbyordinal(0, IntegerType), IntegerType, - root class: "scala.Int"))), obj#2: int   DeserializeToObject assertnotnull(cast(value#1 as int)), obj#2: int
 +- LocalRelation <empty>, [value#1]                                                                                                                          +- LocalRelation <empty>, [value#1]
          
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove TempResolvedColumn after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Remove TempResolvedColumn has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Apply Char Padding after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Apply Char Padding has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Post-Hoc Resolution after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Post-Hoc Resolution has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove Unresolved Hints after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Remove Unresolved Hints has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Nondeterministic after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Nondeterministic has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UDF after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch UDF has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UpdateNullability after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch UpdateNullability has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Subquery after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Subquery has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Cleanup after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Cleanup has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch HandleAnalysisOnlyCommand after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch HandleAnalysisOnlyCommand has no effect.
23/11/10 17:21:16 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 133
Total time: 0.017718514 seconds
Total number of effective runs: 3
Total time of effective runs: 0.010512441 seconds
      
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Substitution after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Substitution has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Disable Hints after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Disable Hints has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Hints after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Hints has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Simple Sanity Check after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Simple Sanity Check has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Keep Legacy Outputs after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Keep Legacy Outputs has no effect.
23/11/10 17:21:16 TRACE Analyzer$ResolveReferences: Attempting to resolve Project [value#1 AS t_col#4]
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Resolution after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Resolution has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove TempResolvedColumn after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Remove TempResolvedColumn has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Apply Char Padding after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Apply Char Padding has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Post-Hoc Resolution after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Post-Hoc Resolution has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove Unresolved Hints after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Remove Unresolved Hints has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Nondeterministic after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Nondeterministic has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UDF after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch UDF has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UpdateNullability after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch UpdateNullability has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Subquery after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Subquery has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Cleanup after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Cleanup has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch HandleAnalysisOnlyCommand after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch HandleAnalysisOnlyCommand has no effect.
23/11/10 17:21:16 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 81
Total time: 0.002742174 seconds
Total number of effective runs: 0
Total time of effective runs: 0.0 seconds
      
23/11/10 17:21:16 DEBUG SparkSqlParser: Parsing command: target
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Substitution after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Substitution has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Disable Hints after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Disable Hints has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Hints after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Hints has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Simple Sanity Check after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Simple Sanity Check has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Keep Legacy Outputs after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Keep Legacy Outputs has no effect.
23/11/10 17:21:16 TRACE Analyzer$ResolveReferences: Attempting to resolve CreateViewCommand `target`, false, true, LocalTempView, true
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Resolution after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Resolution has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove TempResolvedColumn after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Remove TempResolvedColumn has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Apply Char Padding after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Apply Char Padding has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Post-Hoc Resolution after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Post-Hoc Resolution has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove Unresolved Hints after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Remove Unresolved Hints has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Nondeterministic after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Nondeterministic has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UDF after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch UDF has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UpdateNullability after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch UpdateNullability has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Subquery after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Subquery has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Cleanup after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch Cleanup has no effect.
23/11/10 17:21:16 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch HandleAnalysisOnlyCommand after 1 iterations.
23/11/10 17:21:16 TRACE PlanChangeLogger: Batch HandleAnalysisOnlyCommand has no effect.
23/11/10 17:21:16 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 81
Total time: 0.002447259 seconds
Total number of effective runs: 0
Total time of effective runs: 0.0 seconds
      
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Eliminate Distinct after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Eliminate Distinct has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Finish Analysis after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Finish Analysis has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Inline CTE after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Inline CTE has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Union after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Union has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch OptimizeLimitZero after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch OptimizeLimitZero has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch LocalRelation early after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch LocalRelation early has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Pullup Correlated Expressions after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Pullup Correlated Expressions has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Subquery after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Subquery has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Replace Operators after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Replace Operators has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Aggregate after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Aggregate has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Operator Optimization before Inferring Filters after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Operator Optimization before Inferring Filters has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Infer Filters after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Infer Filters has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Operator Optimization after Inferring Filters after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Operator Optimization after Inferring Filters has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Push extra predicate through join after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Push extra predicate through join has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Clean Up Temporary CTE Info after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Clean Up Temporary CTE Info has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Pre CBO Rules after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Pre CBO Rules has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Early Filter and Projection Push-Down after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Early Filter and Projection Push-Down has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Update CTE Relation Stats after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Update CTE Relation Stats has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Join Reorder after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Join Reorder has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Eliminate Sorts after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Eliminate Sorts has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Decimal Optimizations after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Decimal Optimizations has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Distinct Aggregate Rewrite after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Distinct Aggregate Rewrite has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Object Expressions Optimization after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Object Expressions Optimization has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch LocalRelation after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch LocalRelation has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Optimize One Row Plan after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Optimize One Row Plan has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Check Cartesian Products after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Check Cartesian Products has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch RewriteSubquery after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch RewriteSubquery has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch NormalizeFloatingNumbers after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch NormalizeFloatingNumbers has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch ReplaceUpdateFieldsExpression after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch ReplaceUpdateFieldsExpression has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Optimize Metadata Only Query after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Optimize Metadata Only Query has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch PartitionPruning after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch PartitionPruning has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch InjectRuntimeFilter after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch InjectRuntimeFilter has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch MergeScalarSubqueries after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch MergeScalarSubqueries has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Pushdown Filters from PartitionPruning after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Pushdown Filters from PartitionPruning has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Cleanup filters that cannot be pushed down after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Cleanup filters that cannot be pushed down has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Extract Python UDFs after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Extract Python UDFs has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch User Provided Optimizers after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch User Provided Optimizers has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Replace CTE with Repartition after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Replace CTE with Repartition has no effect.
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 174
Total time: 0.063217804 seconds
Total number of effective runs: 0
Total time of effective runs: 0.0 seconds
      
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Preparations has no effect.
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.expressions.codegen.package$ExpressionCanonicalizer$CleanExpressions ===
!input[0, int, false] AS value#6   input[0, int, false]
!+- input[0, int, false]           
           
23/11/10 17:21:17 TRACE package$ExpressionCanonicalizer: Fixed point reached for batch CleanExpressions after 2 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Result of Batch CleanExpressions ===
!input[0, int, false] AS value#6   input[0, int, false]
!+- input[0, int, false]           
          
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 2
Total time: 3.2213E-5 seconds
Total number of effective runs: 1
Total time of effective runs: 1.9926E-5 seconds
      
23/11/10 17:21:17 DEBUG GenerateUnsafeProjection: code for input[0, int, false]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */     int value_0 = i.getInt(0);
/* 032 */     mutableStateArray_0[0].write(0, value_0);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Substitution after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Substitution has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Disable Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Disable Hints has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Hints has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Simple Sanity Check after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Simple Sanity Check has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Keep Legacy Outputs after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Keep Legacy Outputs has no effect.
23/11/10 17:21:17 TRACE Analyzer$ResolveReferences: Attempting to resolve LocalRelation [value#7]
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Resolution after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Resolution has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove TempResolvedColumn after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Remove TempResolvedColumn has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Apply Char Padding after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Apply Char Padding has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Post-Hoc Resolution after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Post-Hoc Resolution has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove Unresolved Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Remove Unresolved Hints has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Nondeterministic after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Nondeterministic has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UDF after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch UDF has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UpdateNullability after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch UpdateNullability has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Subquery after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Subquery has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Cleanup after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Cleanup has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch HandleAnalysisOnlyCommand after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch HandleAnalysisOnlyCommand has no effect.
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 81
Total time: 0.001800892 seconds
Total number of effective runs: 0
Total time of effective runs: 0.0 seconds
      
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Substitution after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Substitution has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Disable Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Disable Hints has no effect.
23/11/10 17:21:17 DEBUG DFSClient: WriteChunk allocating new packet seqno=6, src=/spark3.3.0-logs/local-1699608073397.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=87552, output stream=DFSOutputStream:blk_1073742677_1858
23/11/10 17:21:17 DEBUG DFSClient: DFSClient flush():  bytesCurBlock=91061, lastFlushOffset=87695, createNewBlock=false
23/11/10 17:21:17 DEBUG DataStreamer: Queued packet seqno: 6 offsetInBlock: 87552 lastPacketInBlock: false lastByteOffsetInBlock: 91061, blk_1073742677_1858
23/11/10 17:21:17 DEBUG DataStreamer: blk_1073742677_1858 waiting for ack for: 6
23/11/10 17:21:17 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:17 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 6 offsetInBlock: 87552 lastPacketInBlock: false lastByteOffsetInBlock: 91061
23/11/10 17:21:17 DEBUG DataStreamer: DFSClient seqno: 6 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Hints has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Simple Sanity Check after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Simple Sanity Check has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Keep Legacy Outputs after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Keep Legacy Outputs has no effect.
23/11/10 17:21:17 DEBUG DFSClient: WriteChunk allocating new packet seqno=7, src=/spark3.3.0-logs/local-1699608073397.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=90624, output stream=DFSOutputStream:blk_1073742677_1858
23/11/10 17:21:17 DEBUG DFSClient: DFSClient flush():  bytesCurBlock=91173, lastFlushOffset=91061, createNewBlock=false
23/11/10 17:21:17 DEBUG DataStreamer: Queued packet seqno: 7 offsetInBlock: 90624 lastPacketInBlock: false lastByteOffsetInBlock: 91173, blk_1073742677_1858
23/11/10 17:21:17 DEBUG DataStreamer: blk_1073742677_1858 waiting for ack for: 7
23/11/10 17:21:17 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:17 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 7 offsetInBlock: 90624 lastPacketInBlock: false lastByteOffsetInBlock: 91173
23/11/10 17:21:17 DEBUG DataStreamer: DFSClient seqno: 7 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:17 TRACE Analyzer$ResolveReferences: Attempting to resolve LocalRelation <empty>, [value#7]
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveDeserializer ===
!'DeserializeToObject unresolveddeserializer(assertnotnull(upcast(getcolumnbyordinal(0, IntegerType), IntegerType, - root class: "scala.Int"))), obj#8: int   'DeserializeToObject assertnotnull(upcast(value#7, IntegerType, - root class: "scala.Int")), obj#8: int
 +- LocalRelation <empty>, [value#7]                                                                                                                          +- LocalRelation <empty>, [value#7]
           
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveUpCast ===
!'DeserializeToObject assertnotnull(upcast(value#7, IntegerType, - root class: "scala.Int")), obj#8: int   DeserializeToObject assertnotnull(cast(value#7 as int)), obj#8: int
 +- LocalRelation <empty>, [value#7]                                                                       +- LocalRelation <empty>, [value#7]
           
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.analysis.ResolveTimeZone ===
 DeserializeToObject assertnotnull(cast(value#7 as int)), obj#8: int   DeserializeToObject assertnotnull(cast(value#7 as int)), obj#8: int
 +- LocalRelation <empty>, [value#7]                                   +- LocalRelation <empty>, [value#7]
           
23/11/10 17:21:17 TRACE Analyzer$ResolveReferences: Attempting to resolve DeserializeToObject assertnotnull(cast(value#7 as int)), obj#8: int
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Resolution after 2 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(assertnotnull(upcast(getcolumnbyordinal(0, IntegerType), IntegerType, - root class: "scala.Int"))), obj#8: int   DeserializeToObject assertnotnull(cast(value#7 as int)), obj#8: int
 +- LocalRelation <empty>, [value#7]                                                                                                                          +- LocalRelation <empty>, [value#7]
          
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove TempResolvedColumn after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Remove TempResolvedColumn has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Apply Char Padding after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Apply Char Padding has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Post-Hoc Resolution after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Post-Hoc Resolution has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove Unresolved Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Remove Unresolved Hints has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Nondeterministic after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Nondeterministic has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UDF after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch UDF has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UpdateNullability after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch UpdateNullability has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Subquery after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Subquery has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Cleanup after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Cleanup has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch HandleAnalysisOnlyCommand after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch HandleAnalysisOnlyCommand has no effect.
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 133
Total time: 0.003319528 seconds
Total number of effective runs: 3
Total time of effective runs: 6.5455E-4 seconds
      
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Substitution after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Substitution has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Disable Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Disable Hints has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Hints has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Simple Sanity Check after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Simple Sanity Check has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Keep Legacy Outputs after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Keep Legacy Outputs has no effect.
23/11/10 17:21:17 TRACE Analyzer$ResolveReferences: Attempting to resolve Project [value#7 AS s_col#10]
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Resolution after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Resolution has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove TempResolvedColumn after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Remove TempResolvedColumn has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Apply Char Padding after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Apply Char Padding has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Post-Hoc Resolution after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Post-Hoc Resolution has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove Unresolved Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Remove Unresolved Hints has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Nondeterministic after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Nondeterministic has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UDF after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch UDF has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UpdateNullability after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch UpdateNullability has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Subquery after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Subquery has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Cleanup after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Cleanup has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch HandleAnalysisOnlyCommand after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch HandleAnalysisOnlyCommand has no effect.
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 81
Total time: 0.001216018 seconds
Total number of effective runs: 0
Total time of effective runs: 0.0 seconds
      
23/11/10 17:21:17 DEBUG SparkSqlParser: Parsing command: source
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Substitution after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Substitution has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Disable Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Disable Hints has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Hints has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Simple Sanity Check after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Simple Sanity Check has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Keep Legacy Outputs after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Keep Legacy Outputs has no effect.
23/11/10 17:21:17 TRACE Analyzer$ResolveReferences: Attempting to resolve CreateViewCommand `source`, false, true, LocalTempView, true
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Resolution after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Resolution has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove TempResolvedColumn after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Remove TempResolvedColumn has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Apply Char Padding after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Apply Char Padding has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Post-Hoc Resolution after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Post-Hoc Resolution has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove Unresolved Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Remove Unresolved Hints has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Nondeterministic after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Nondeterministic has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UDF after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch UDF has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UpdateNullability after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch UpdateNullability has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Subquery after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Subquery has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Cleanup after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Cleanup has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch HandleAnalysisOnlyCommand after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch HandleAnalysisOnlyCommand has no effect.
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 81
Total time: 8.37449E-4 seconds
Total number of effective runs: 0
Total time of effective runs: 0.0 seconds
      
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Eliminate Distinct after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Eliminate Distinct has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Finish Analysis after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Finish Analysis has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Inline CTE after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Inline CTE has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Union after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Union has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch OptimizeLimitZero after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch OptimizeLimitZero has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch LocalRelation early after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch LocalRelation early has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Pullup Correlated Expressions after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Pullup Correlated Expressions has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Subquery after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Subquery has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Replace Operators after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Replace Operators has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Aggregate after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Aggregate has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Operator Optimization before Inferring Filters after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Operator Optimization before Inferring Filters has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Infer Filters after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Infer Filters has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Operator Optimization after Inferring Filters after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Operator Optimization after Inferring Filters has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Push extra predicate through join after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Push extra predicate through join has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Clean Up Temporary CTE Info after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Clean Up Temporary CTE Info has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Pre CBO Rules after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Pre CBO Rules has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Early Filter and Projection Push-Down after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Early Filter and Projection Push-Down has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Update CTE Relation Stats after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Update CTE Relation Stats has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Join Reorder after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Join Reorder has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Eliminate Sorts after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Eliminate Sorts has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Decimal Optimizations after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Decimal Optimizations has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Distinct Aggregate Rewrite after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Distinct Aggregate Rewrite has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Object Expressions Optimization after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Object Expressions Optimization has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch LocalRelation after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch LocalRelation has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Optimize One Row Plan after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Optimize One Row Plan has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Check Cartesian Products after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Check Cartesian Products has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch RewriteSubquery after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch RewriteSubquery has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch NormalizeFloatingNumbers after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch NormalizeFloatingNumbers has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch ReplaceUpdateFieldsExpression after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch ReplaceUpdateFieldsExpression has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Optimize Metadata Only Query after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Optimize Metadata Only Query has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch PartitionPruning after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch PartitionPruning has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch InjectRuntimeFilter after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch InjectRuntimeFilter has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch MergeScalarSubqueries after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch MergeScalarSubqueries has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Pushdown Filters from PartitionPruning after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Pushdown Filters from PartitionPruning has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Cleanup filters that cannot be pushed down after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Cleanup filters that cannot be pushed down has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Extract Python UDFs after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Extract Python UDFs has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch User Provided Optimizers after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch User Provided Optimizers has no effect.
23/11/10 17:21:17 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Replace CTE with Repartition after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Replace CTE with Repartition has no effect.
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 174
Total time: 0.002108119 seconds
Total number of effective runs: 0
Total time of effective runs: 0.0 seconds
      
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Preparations has no effect.
23/11/10 17:21:17 DEBUG DFSClient: WriteChunk allocating new packet seqno=8, src=/spark3.3.0-logs/local-1699608073397.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=91136, output stream=DFSOutputStream:blk_1073742677_1858
23/11/10 17:21:17 DEBUG DFSClient: DFSClient flush():  bytesCurBlock=94540, lastFlushOffset=91173, createNewBlock=false
23/11/10 17:21:17 DEBUG DataStreamer: Queued packet seqno: 8 offsetInBlock: 91136 lastPacketInBlock: false lastByteOffsetInBlock: 94540, blk_1073742677_1858
23/11/10 17:21:17 DEBUG DataStreamer: blk_1073742677_1858 waiting for ack for: 8
23/11/10 17:21:17 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:17 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 8 offsetInBlock: 91136 lastPacketInBlock: false lastByteOffsetInBlock: 94540
23/11/10 17:21:17 DEBUG SparkSqlParser: Parsing command: SELECT * FROM target t WHERE EXISTS (SELECT /*+ BROADCAST(t) */ * FROM source s WHERE t.t_col = s.s_col);
23/11/10 17:21:17 DEBUG DataStreamer: DFSClient seqno: 8 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:17 DEBUG DFSClient: WriteChunk allocating new packet seqno=9, src=/spark3.3.0-logs/local-1699608073397.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=94208, output stream=DFSOutputStream:blk_1073742677_1858
23/11/10 17:21:17 DEBUG DFSClient: DFSClient flush():  bytesCurBlock=94652, lastFlushOffset=94540, createNewBlock=false
23/11/10 17:21:17 DEBUG DataStreamer: Queued packet seqno: 9 offsetInBlock: 94208 lastPacketInBlock: false lastByteOffsetInBlock: 94652, blk_1073742677_1858
23/11/10 17:21:17 DEBUG DataStreamer: blk_1073742677_1858 waiting for ack for: 9
23/11/10 17:21:17 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:17 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 9 offsetInBlock: 94208 lastPacketInBlock: false lastByteOffsetInBlock: 94652
23/11/10 17:21:17 DEBUG DataStreamer: DFSClient seqno: 9 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Substitution after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Substitution has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Disable Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Disable Hints has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Hints has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Simple Sanity Check after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Simple Sanity Check has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Keep Legacy Outputs after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Keep Legacy Outputs has no effect.
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations ===
 'Project [*]                                                   'Project [*]
 +- 'Filter exists#12 []                                        +- 'Filter exists#12 []
    :  +- 'UnresolvedHint BROADCAST, ['t]                          :  +- 'UnresolvedHint BROADCAST, ['t]
    :     +- 'Project [*]                                          :     +- 'Project [*]
    :        +- 'Filter ('t.t_col = 's.s_col)                      :        +- 'Filter ('t.t_col = 's.s_col)
    :           +- 'SubqueryAlias s                                :           +- 'SubqueryAlias s
    :              +- 'UnresolvedRelation [source], [], false      :              +- 'UnresolvedRelation [source], [], false
!   +- 'SubqueryAlias t                                            +- SubqueryAlias t
!      +- 'UnresolvedRelation [target], [], false                     +- SubqueryAlias target
!                                                                        +- View (`target`, [t_col#4])
!                                                                           +- Project [value#1 AS t_col#4]
!                                                                              +- LocalRelation [value#1]
           
23/11/10 17:21:17 TRACE Analyzer$ResolveReferences: Attempting to resolve View (`target`, [t_col#4])
23/11/10 17:21:17 TRACE Analyzer$ResolveReferences: Attempting to resolve SubqueryAlias target
23/11/10 17:21:17 TRACE Analyzer$ResolveReferences: Attempting to resolve SubqueryAlias t
23/11/10 17:21:17 TRACE Analyzer$ResolveReferences: Attempting to resolve 'Filter exists#12 []
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Substitution after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Substitution has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Disable Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Disable Hints has no effect.
23/11/10 17:21:17 WARN HintErrorLogger: Count not find relation 't' specified in hint 'BROADCAST(t)'.
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.analysis.ResolveHints$ResolveJoinStrategyHints ===
!'UnresolvedHint BROADCAST, ['t]                       'Project [*]
!+- 'Project [*]                                       +- 'Filter ('t.t_col = 's.s_col)
!   +- 'Filter ('t.t_col = 's.s_col)                      +- 'SubqueryAlias s
!      +- 'SubqueryAlias s                                   +- 'UnresolvedRelation [source], [], false
!         +- 'UnresolvedRelation [source], [], false   
           
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Hints after 2 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Result of Batch Hints ===
!'UnresolvedHint BROADCAST, ['t]                       'Project [*]
!+- 'Project [*]                                       +- 'Filter ('t.t_col = 's.s_col)
!   +- 'Filter ('t.t_col = 's.s_col)                      +- 'SubqueryAlias s
!      +- 'SubqueryAlias s                                   +- 'UnresolvedRelation [source], [], false
!         +- 'UnresolvedRelation [source], [], false   
          
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Simple Sanity Check after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Simple Sanity Check has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Keep Legacy Outputs after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Keep Legacy Outputs has no effect.
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations ===
 'Project [*]                                       'Project [*]
 +- 'Filter ('t.t_col = 's.s_col)                   +- 'Filter ('t.t_col = 's.s_col)
!   +- 'SubqueryAlias s                                +- SubqueryAlias s
!      +- 'UnresolvedRelation [source], [], false         +- SubqueryAlias source
!                                                            +- View (`source`, [s_col#10])
!                                                               +- Project [value#7 AS s_col#10]
!                                                                  +- LocalRelation [value#7]
           
23/11/10 17:21:17 TRACE Analyzer$ResolveReferences: Attempting to resolve View (`source`, [s_col#10])
23/11/10 17:21:17 TRACE Analyzer$ResolveReferences: Attempting to resolve SubqueryAlias source
23/11/10 17:21:17 TRACE Analyzer$ResolveReferences: Attempting to resolve SubqueryAlias s
23/11/10 17:21:17 TRACE Analyzer$ResolveReferences: Attempting to resolve 'Filter ('t.t_col = 's.s_col)
23/11/10 17:21:17 DEBUG HiveSessionStateBuilder$$anon$1: Resolving 't.t_col to 't.t_col
23/11/10 17:21:17 DEBUG HiveSessionStateBuilder$$anon$1: Resolving 's.s_col to s_col#10
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences ===
 'Project [*]                                   'Project [*]
!+- 'Filter ('t.t_col = 's.s_col)               +- 'Filter ('t.t_col = s_col#10)
    +- SubqueryAlias s                             +- SubqueryAlias s
       +- SubqueryAlias source                        +- SubqueryAlias source
          +- View (`source`, [s_col#10])                 +- View (`source`, [s_col#10])
             +- Project [value#7 AS s_col#10]               +- Project [value#7 AS s_col#10]
                +- LocalRelation [value#7]                     +- LocalRelation [value#7]
           
23/11/10 17:21:17 DEBUG HiveSessionStateBuilder$$anon$1: Resolving 't.t_col to 't.t_col
23/11/10 17:21:17 TRACE Analyzer$ResolveReferences: Attempting to resolve 'Filter ('t.t_col = s_col#10)
23/11/10 17:21:17 DEBUG HiveSessionStateBuilder$$anon$1: Resolving 't.t_col to 't.t_col
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Resolution after 2 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Result of Batch Resolution ===
 'Project [*]                                       'Project [*]
!+- 'Filter ('t.t_col = 's.s_col)                   +- 'Filter ('t.t_col = s_col#10)
!   +- 'SubqueryAlias s                                +- SubqueryAlias s
!      +- 'UnresolvedRelation [source], [], false         +- SubqueryAlias source
!                                                            +- View (`source`, [s_col#10])
!                                                               +- Project [value#7 AS s_col#10]
!                                                                  +- LocalRelation [value#7]
          
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove TempResolvedColumn after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Remove TempResolvedColumn has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Apply Char Padding after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Apply Char Padding has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Post-Hoc Resolution after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Post-Hoc Resolution has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove Unresolved Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Remove Unresolved Hints has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Nondeterministic after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Nondeterministic has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UDF after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch UDF has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UpdateNullability after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch UpdateNullability has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Subquery after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Subquery has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Cleanup after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Cleanup has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch HandleAnalysisOnlyCommand after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch HandleAnalysisOnlyCommand has no effect.
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 135
Total time: 0.013576686 seconds
Total number of effective runs: 3
Total time of effective runs: 0.007372645 seconds
      
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Substitution after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Substitution has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Disable Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Disable Hints has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Hints after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Hints has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Simple Sanity Check after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Simple Sanity Check has no effect.
23/11/10 17:21:17 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Keep Legacy Outputs after 1 iterations.
23/11/10 17:21:17 TRACE PlanChangeLogger: Batch Keep Legacy Outputs has no effect.
23/11/10 17:21:17 TRACE Analyzer$ResolveReferences: Attempting to resolve Filter (outer(t_col#4) = s_col#10)
23/11/10 17:21:17 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences ===
!'Project [*]                                   Project [s_col#10]
 +- Filter (outer(t_col#4) = s_col#10)          +- Filter (outer(t_col#4) = s_col#10)
    +- SubqueryAlias s                             +- SubqueryAlias s
       +- SubqueryAlias source                        +- SubqueryAlias source
          +- View (`source`, [s_col#10])                 +- View (`source`, [s_col#10])
             +- Project [value#7 AS s_col#10]               +- Project [value#7 AS s_col#10]
                +- LocalRelation [value#7]                     +- LocalRelation [value#7]
           
23/11/10 17:21:17 TRACE Analyzer$ResolveReferences: Attempting to resolve Project [s_col#10]
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Resolution after 2 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Result of Batch Resolution ===
!'Project [*]                                   Project [s_col#10]
 +- Filter (outer(t_col#4) = s_col#10)          +- Filter (outer(t_col#4) = s_col#10)
    +- SubqueryAlias s                             +- SubqueryAlias s
       +- SubqueryAlias source                        +- SubqueryAlias source
          +- View (`source`, [s_col#10])                 +- View (`source`, [s_col#10])
             +- Project [value#7 AS s_col#10]               +- Project [value#7 AS s_col#10]
                +- LocalRelation [value#7]                     +- LocalRelation [value#7]
          
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove TempResolvedColumn after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Remove TempResolvedColumn has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Apply Char Padding after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Apply Char Padding has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Post-Hoc Resolution after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Post-Hoc Resolution has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove Unresolved Hints after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Remove Unresolved Hints has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Nondeterministic after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Nondeterministic has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UDF after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch UDF has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UpdateNullability after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch UpdateNullability has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Subquery after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Subquery has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Cleanup after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Cleanup has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch HandleAnalysisOnlyCommand after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch HandleAnalysisOnlyCommand has no effect.
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 133
Total time: 0.006846942 seconds
Total number of effective runs: 1
Total time of effective runs: 7.93362E-4 seconds
      
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveSubquery ===
 'Project [*]                                                   'Project [*]
!+- 'Filter exists#12 []                                        +- Filter exists#12 [t_col#4]
!   :  +- 'UnresolvedHint BROADCAST, ['t]                          :  +- Project [s_col#10]
!   :     +- 'Project [*]                                          :     +- Filter (outer(t_col#4) = s_col#10)
!   :        +- 'Filter ('t.t_col = 's.s_col)                      :        +- SubqueryAlias s
!   :           +- 'SubqueryAlias s                                :           +- SubqueryAlias source
!   :              +- 'UnresolvedRelation [source], [], false      :              +- View (`source`, [s_col#10])
!   +- SubqueryAlias t                                             :                 +- Project [value#7 AS s_col#10]
!      +- SubqueryAlias target                                     :                    +- LocalRelation [value#7]
!         +- View (`target`, [t_col#4])                            +- SubqueryAlias t
!            +- Project [value#1 AS t_col#4]                          +- SubqueryAlias target
!               +- LocalRelation [value#1]                               +- View (`target`, [t_col#4])
!                                                                           +- Project [value#1 AS t_col#4]
!                                                                              +- LocalRelation [value#1]
           
23/11/10 17:21:18 TRACE Analyzer$ResolveReferences: Attempting to resolve Filter exists#12 [t_col#4]
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences ===
!'Project [*]                                            Project [t_col#4]
 +- Filter exists#12 [t_col#4]                           +- Filter exists#12 [t_col#4]
    :  +- Project [s_col#10]                                :  +- Project [s_col#10]
    :     +- Filter (outer(t_col#4) = s_col#10)             :     +- Filter (outer(t_col#4) = s_col#10)
    :        +- SubqueryAlias s                             :        +- SubqueryAlias s
    :           +- SubqueryAlias source                     :           +- SubqueryAlias source
    :              +- View (`source`, [s_col#10])           :              +- View (`source`, [s_col#10])
    :                 +- Project [value#7 AS s_col#10]      :                 +- Project [value#7 AS s_col#10]
    :                    +- LocalRelation [value#7]         :                    +- LocalRelation [value#7]
    +- SubqueryAlias t                                      +- SubqueryAlias t
       +- SubqueryAlias target                                 +- SubqueryAlias target
          +- View (`target`, [t_col#4])                           +- View (`target`, [t_col#4])
             +- Project [value#1 AS t_col#4]                         +- Project [value#1 AS t_col#4]
                +- LocalRelation [value#1]                              +- LocalRelation [value#1]
           
23/11/10 17:21:18 TRACE Analyzer$ResolveReferences: Attempting to resolve Project [t_col#4]
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Resolution after 3 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Result of Batch Resolution ===
!'Project [*]                                                   Project [t_col#4]
!+- 'Filter exists#12 []                                        +- Filter exists#12 [t_col#4]
!   :  +- 'UnresolvedHint BROADCAST, ['t]                          :  +- Project [s_col#10]
!   :     +- 'Project [*]                                          :     +- Filter (outer(t_col#4) = s_col#10)
!   :        +- 'Filter ('t.t_col = 's.s_col)                      :        +- SubqueryAlias s
!   :           +- 'SubqueryAlias s                                :           +- SubqueryAlias source
!   :              +- 'UnresolvedRelation [source], [], false      :              +- View (`source`, [s_col#10])
!   +- 'SubqueryAlias t                                            :                 +- Project [value#7 AS s_col#10]
!      +- 'UnresolvedRelation [target], [], false                  :                    +- LocalRelation [value#7]
!                                                                  +- SubqueryAlias t
!                                                                     +- SubqueryAlias target
!                                                                        +- View (`target`, [t_col#4])
!                                                                           +- Project [value#1 AS t_col#4]
!                                                                              +- LocalRelation [value#1]
          
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove TempResolvedColumn after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Remove TempResolvedColumn has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Apply Char Padding after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Apply Char Padding has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Post-Hoc Resolution after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Post-Hoc Resolution has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove Unresolved Hints after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Remove Unresolved Hints has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Nondeterministic after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Nondeterministic has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UDF after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch UDF has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UpdateNullability after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch UpdateNullability has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Subquery after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Subquery has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Cleanup after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Cleanup has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch HandleAnalysisOnlyCommand after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch HandleAnalysisOnlyCommand has no effect.
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 453
Total time: 0.359714906 seconds
Total number of effective runs: 7
Total time of effective runs: 0.342898257 seconds
      
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Eliminate Distinct after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Eliminate Distinct has no effect.
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.optimizer.Optimizer$FinishAnalysis ===
 Project [t_col#4]                                       Project [t_col#4]
 +- Filter exists#12 [t_col#4]                           +- Filter exists#12 [t_col#4]
    :  +- Project [s_col#10]                                :  +- Project [s_col#10]
    :     +- Filter (outer(t_col#4) = s_col#10)             :     +- Filter (outer(t_col#4) = s_col#10)
!   :        +- SubqueryAlias s                             :        +- Project [value#7 AS s_col#10]
!   :           +- SubqueryAlias source                     :           +- LocalRelation [value#7]
!   :              +- View (`source`, [s_col#10])           +- Project [value#1 AS t_col#4]
!   :                 +- Project [value#7 AS s_col#10]         +- LocalRelation [value#1]
!   :                    +- LocalRelation [value#7]      
!   +- SubqueryAlias t                                   
!      +- SubqueryAlias target                           
!         +- View (`target`, [t_col#4])                  
!            +- Project [value#1 AS t_col#4]             
!               +- LocalRelation [value#1]               
           
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Result of Batch Finish Analysis ===
 Project [t_col#4]                                       Project [t_col#4]
 +- Filter exists#12 [t_col#4]                           +- Filter exists#12 [t_col#4]
    :  +- Project [s_col#10]                                :  +- Project [s_col#10]
    :     +- Filter (outer(t_col#4) = s_col#10)             :     +- Filter (outer(t_col#4) = s_col#10)
!   :        +- SubqueryAlias s                             :        +- Project [value#7 AS s_col#10]
!   :           +- SubqueryAlias source                     :           +- LocalRelation [value#7]
!   :              +- View (`source`, [s_col#10])           +- Project [value#1 AS t_col#4]
!   :                 +- Project [value#7 AS s_col#10]         +- LocalRelation [value#1]
!   :                    +- LocalRelation [value#7]      
!   +- SubqueryAlias t                                   
!      +- SubqueryAlias target                           
!         +- View (`target`, [t_col#4])                  
!            +- Project [value#1 AS t_col#4]             
!               +- LocalRelation [value#1]               
          
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Inline CTE after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Inline CTE has no effect.
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.optimizer.RemoveNoopOperators ===
!Project [t_col#4]                                Filter exists#12 [t_col#4]
!+- Filter exists#12 [t_col#4]                    :  +- Project [s_col#10]
!   :  +- Project [s_col#10]                      :     +- Filter (outer(t_col#4) = s_col#10)
!   :     +- Filter (outer(t_col#4) = s_col#10)   :        +- Project [value#7 AS s_col#10]
!   :        +- Project [value#7 AS s_col#10]     :           +- LocalRelation [value#7]
!   :           +- LocalRelation [value#7]        +- Project [value#1 AS t_col#4]
!   +- Project [value#1 AS t_col#4]                  +- LocalRelation [value#1]
!      +- LocalRelation [value#1]                 
           
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Result of Batch Union ===
!Project [t_col#4]                                Filter exists#12 [t_col#4]
!+- Filter exists#12 [t_col#4]                    :  +- Project [s_col#10]
!   :  +- Project [s_col#10]                      :     +- Filter (outer(t_col#4) = s_col#10)
!   :     +- Filter (outer(t_col#4) = s_col#10)   :        +- Project [value#7 AS s_col#10]
!   :        +- Project [value#7 AS s_col#10]     :           +- LocalRelation [value#7]
!   :           +- LocalRelation [value#7]        +- Project [value#1 AS t_col#4]
!   +- Project [value#1 AS t_col#4]                  +- LocalRelation [value#1]
!      +- LocalRelation [value#1]                 
          
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch OptimizeLimitZero after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch OptimizeLimitZero has no effect.
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.optimizer.ConvertToLocalRelation ===
 Filter exists#12 [t_col#4]                    Filter exists#12 [t_col#4]
 :  +- Project [s_col#10]                      :  +- Project [s_col#10]
 :     +- Filter (outer(t_col#4) = s_col#10)   :     +- Filter (outer(t_col#4) = s_col#10)
 :        +- Project [value#7 AS s_col#10]     :        +- Project [value#7 AS s_col#10]
 :           +- LocalRelation [value#7]        :           +- LocalRelation [value#7]
!+- Project [value#1 AS t_col#4]               +- LocalRelation [t_col#4]
!   +- LocalRelation [value#1]                 
           
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch LocalRelation early after 2 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Result of Batch LocalRelation early ===
 Filter exists#12 [t_col#4]                    Filter exists#12 [t_col#4]
 :  +- Project [s_col#10]                      :  +- Project [s_col#10]
 :     +- Filter (outer(t_col#4) = s_col#10)   :     +- Filter (outer(t_col#4) = s_col#10)
 :        +- Project [value#7 AS s_col#10]     :        +- Project [value#7 AS s_col#10]
 :           +- LocalRelation [value#7]        :           +- LocalRelation [value#7]
!+- Project [value#1 AS t_col#4]               +- LocalRelation [t_col#4]
!   +- LocalRelation [value#1]                 
          
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.optimizer.PullupCorrelatedPredicates ===
!Filter exists#12 [t_col#4]                    Filter exists#12 [t_col#4 && (t_col#4 = s_col#10)]
 :  +- Project [s_col#10]                      :  +- Project [s_col#10]
!:     +- Filter (outer(t_col#4) = s_col#10)   :     +- Project [value#7 AS s_col#10]
!:        +- Project [value#7 AS s_col#10]     :        +- LocalRelation [value#7]
!:           +- LocalRelation [value#7]        +- LocalRelation [t_col#4]
!+- LocalRelation [t_col#4]                    
           
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Result of Batch Pullup Correlated Expressions ===
!Filter exists#12 [t_col#4]                    Filter exists#12 [t_col#4 && (t_col#4 = s_col#10)]
 :  +- Project [s_col#10]                      :  +- Project [s_col#10]
!:     +- Filter (outer(t_col#4) = s_col#10)   :     +- Project [value#7 AS s_col#10]
!:        +- Project [value#7 AS s_col#10]     :        +- LocalRelation [value#7]
!:           +- LocalRelation [value#7]        +- LocalRelation [t_col#4]
!+- LocalRelation [t_col#4]                    
          
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Eliminate Distinct after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Eliminate Distinct has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Finish Analysis after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Finish Analysis has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Inline CTE after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Inline CTE has no effect.
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.optimizer.RemoveNoopOperators ===
 Subquery true                         Subquery true
!+- Project [s_col#10]                 +- Project [value#7 AS s_col#10]
!   +- Project [value#7 AS s_col#10]      +- LocalRelation [value#7]
!      +- LocalRelation [value#7]      
           
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Result of Batch Union ===
 Subquery true                         Subquery true
!+- Project [s_col#10]                 +- Project [value#7 AS s_col#10]
!   +- Project [value#7 AS s_col#10]      +- LocalRelation [value#7]
!      +- LocalRelation [value#7]      
          
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch OptimizeLimitZero after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch OptimizeLimitZero has no effect.
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.optimizer.ConvertToLocalRelation ===
 Subquery true                      Subquery true
!+- Project [value#7 AS s_col#10]   +- LocalRelation [s_col#10]
!   +- LocalRelation [value#7]      
           
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch LocalRelation early after 2 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Result of Batch LocalRelation early ===
 Subquery true                      Subquery true
!+- Project [value#7 AS s_col#10]   +- LocalRelation [s_col#10]
!   +- LocalRelation [value#7]      
          
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Pullup Correlated Expressions after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Pullup Correlated Expressions has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Subquery after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Subquery has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Replace Operators after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Replace Operators has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Aggregate after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Aggregate has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Operator Optimization before Inferring Filters after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Operator Optimization before Inferring Filters has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Infer Filters after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Infer Filters has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Operator Optimization after Inferring Filters after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Operator Optimization after Inferring Filters has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Push extra predicate through join after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Push extra predicate through join has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Clean Up Temporary CTE Info after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Clean Up Temporary CTE Info has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Pre CBO Rules after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Pre CBO Rules has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Early Filter and Projection Push-Down after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Early Filter and Projection Push-Down has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Update CTE Relation Stats after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Update CTE Relation Stats has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Join Reorder after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Join Reorder has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Eliminate Sorts after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Eliminate Sorts has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Decimal Optimizations after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Decimal Optimizations has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Distinct Aggregate Rewrite after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Distinct Aggregate Rewrite has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Object Expressions Optimization after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Object Expressions Optimization has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch LocalRelation after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch LocalRelation has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Optimize One Row Plan after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Optimize One Row Plan has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Check Cartesian Products after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Check Cartesian Products has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch RewriteSubquery after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch RewriteSubquery has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch NormalizeFloatingNumbers after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch NormalizeFloatingNumbers has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch ReplaceUpdateFieldsExpression after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch ReplaceUpdateFieldsExpression has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Optimize Metadata Only Query after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Optimize Metadata Only Query has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch PartitionPruning after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch PartitionPruning has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch InjectRuntimeFilter after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch InjectRuntimeFilter has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch MergeScalarSubqueries after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch MergeScalarSubqueries has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Pushdown Filters from PartitionPruning after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Pushdown Filters from PartitionPruning has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Cleanup filters that cannot be pushed down after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Cleanup filters that cannot be pushed down has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Extract Python UDFs after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Extract Python UDFs has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch User Provided Optimizers after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch User Provided Optimizers has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Replace CTE with Repartition after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Replace CTE with Repartition has no effect.
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 177
Total time: 0.004757756 seconds
Total number of effective runs: 2
Total time of effective runs: 0.001873359 seconds
      
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.optimizer.Optimizer$OptimizeSubqueries ===
 Filter exists#12 [t_col#4 && (t_col#4 = s_col#10)]   Filter exists#12 [t_col#4 && (t_col#4 = s_col#10)]
!:  +- Project [s_col#10]                             :  +- LocalRelation [s_col#10]
!:     +- Project [value#7 AS s_col#10]               +- LocalRelation [t_col#4]
!:        +- LocalRelation [value#7]                  
!+- LocalRelation [t_col#4]                           
           
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Result of Batch Subquery ===
 Filter exists#12 [t_col#4 && (t_col#4 = s_col#10)]   Filter exists#12 [t_col#4 && (t_col#4 = s_col#10)]
!:  +- Project [s_col#10]                             :  +- LocalRelation [s_col#10]
!:     +- Project [value#7 AS s_col#10]               +- LocalRelation [t_col#4]
!:        +- LocalRelation [value#7]                  
!+- LocalRelation [t_col#4]                           
          
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Replace Operators after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Replace Operators has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Aggregate after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Aggregate has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Operator Optimization before Inferring Filters after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Operator Optimization before Inferring Filters has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Infer Filters after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Infer Filters has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Operator Optimization after Inferring Filters after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Operator Optimization after Inferring Filters has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Push extra predicate through join after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Push extra predicate through join has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Clean Up Temporary CTE Info after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Clean Up Temporary CTE Info has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Pre CBO Rules after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Pre CBO Rules has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Early Filter and Projection Push-Down after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Early Filter and Projection Push-Down has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Update CTE Relation Stats after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Update CTE Relation Stats has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Join Reorder after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Join Reorder has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Eliminate Sorts after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Eliminate Sorts has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Decimal Optimizations after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Decimal Optimizations has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Distinct Aggregate Rewrite after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Distinct Aggregate Rewrite has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Object Expressions Optimization after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Object Expressions Optimization has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch LocalRelation after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch LocalRelation has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Optimize One Row Plan after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Optimize One Row Plan has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Check Cartesian Products after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Check Cartesian Products has no effect.
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.optimizer.RewritePredicateSubquery ===
!Filter exists#12 [t_col#4 && (t_col#4 = s_col#10)]   Join LeftSemi, (t_col#4 = s_col#10)
!:  +- LocalRelation [s_col#10]                       :- LocalRelation [t_col#4]
!+- LocalRelation [t_col#4]                           +- LocalRelation [s_col#10]
           
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Result of Batch RewriteSubquery ===
!Filter exists#12 [t_col#4 && (t_col#4 = s_col#10)]   Join LeftSemi, (t_col#4 = s_col#10)
!:  +- LocalRelation [s_col#10]                       :- LocalRelation [t_col#4]
!+- LocalRelation [t_col#4]                           +- LocalRelation [s_col#10]
          
23/11/10 17:21:18 DEBUG ExtractEquiJoinKeys: Considering join on: Some((t_col#4 = s_col#10))
23/11/10 17:21:18 DEBUG ExtractEquiJoinKeys: leftKeys:List(t_col#4) | rightKeys:List(s_col#10)
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch NormalizeFloatingNumbers after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch NormalizeFloatingNumbers has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch ReplaceUpdateFieldsExpression after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch ReplaceUpdateFieldsExpression has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Optimize Metadata Only Query after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Optimize Metadata Only Query has no effect.
23/11/10 17:21:18 DEBUG ExtractEquiJoinKeys: Considering join on: Some((t_col#4 = s_col#10))
23/11/10 17:21:18 DEBUG ExtractEquiJoinKeys: leftKeys:List(t_col#4) | rightKeys:List(s_col#10)
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch PartitionPruning after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch PartitionPruning has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch InjectRuntimeFilter after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch InjectRuntimeFilter has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch MergeScalarSubqueries after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch MergeScalarSubqueries has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Pushdown Filters from PartitionPruning after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Pushdown Filters from PartitionPruning has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Cleanup filters that cannot be pushed down after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Cleanup filters that cannot be pushed down has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Extract Python UDFs after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Extract Python UDFs has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch User Provided Optimizers after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch User Provided Optimizers has no effect.
23/11/10 17:21:18 TRACE BaseSessionStateBuilder$$anon$2: Fixed point reached for batch Replace CTE with Repartition after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Replace CTE with Repartition has no effect.
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 354
Total time: 0.082966675 seconds
Total number of effective runs: 8
Total time of effective runs: 0.061553916 seconds
      
23/11/10 17:21:18 DEBUG ExtractEquiJoinKeys: Considering join on: Some((t_col#4 = s_col#10))
23/11/10 17:21:18 DEBUG ExtractEquiJoinKeys: leftKeys:List(t_col#4) | rightKeys:List(s_col#10)
23/11/10 17:21:18 DEBUG ExtractEquiJoinKeys: Considering join on: Some((t_col#4 = s_col#10))
23/11/10 17:21:18 DEBUG ExtractEquiJoinKeys: leftKeys:List(t_col#4) | rightKeys:List(s_col#10)
23/11/10 17:21:18 DEBUG InsertAdaptiveSparkPlan: Adaptive execution enabled for plan: BroadcastHashJoin [t_col#4], [s_col#10], LeftSemi, BuildRight, false
:- LocalTableScan [t_col#4]
+- LocalTableScan [s_col#10]

23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.execution.exchange.EnsureRequirements ===
 BroadcastHashJoin [t_col#4], [s_col#10], LeftSemi, BuildRight, false   BroadcastHashJoin [t_col#4], [s_col#10], LeftSemi, BuildRight, false
 :- LocalTableScan [t_col#4]                                            :- LocalTableScan [t_col#4]
!+- LocalTableScan [s_col#10]                                           +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#18]
!                                                                          +- LocalTableScan [s_col#10]
           
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Result of Batch AQE Preparations ===
 BroadcastHashJoin [t_col#4], [s_col#10], LeftSemi, BuildRight, false   BroadcastHashJoin [t_col#4], [s_col#10], LeftSemi, BuildRight, false
 :- LocalTableScan [t_col#4]                                            :- LocalTableScan [t_col#4]
!+- LocalTableScan [s_col#10]                                           +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#18]
!                                                                          +- LocalTableScan [s_col#10]
          
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.execution.adaptive.InsertAdaptiveSparkPlan ===
!BroadcastHashJoin [t_col#4], [s_col#10], LeftSemi, BuildRight, false   AdaptiveSparkPlan isFinalPlan=false
!:- LocalTableScan [t_col#4]                                            +- BroadcastHashJoin [t_col#4], [s_col#10], LeftSemi, BuildRight, false
!+- LocalTableScan [s_col#10]                                              :- LocalTableScan [t_col#4]
!                                                                          +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#18]
!                                                                             +- LocalTableScan [s_col#10]
           
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Result of Batch Preparations ===
!BroadcastHashJoin [t_col#4], [s_col#10], LeftSemi, BuildRight, false   AdaptiveSparkPlan isFinalPlan=false
!:- LocalTableScan [t_col#4]                                            +- BroadcastHashJoin [t_col#4], [s_col#10], LeftSemi, BuildRight, false
!+- LocalTableScan [s_col#10]                                              :- LocalTableScan [t_col#4]
!                                                                          +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#18]
!                                                                             +- LocalTableScan [s_col#10]
          
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Substitution after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Substitution has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Disable Hints after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Disable Hints has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Hints after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Hints has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Simple Sanity Check after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Simple Sanity Check has no effect.
23/11/10 17:21:18 DEBUG DFSClient: WriteChunk allocating new packet seqno=10, src=/spark3.3.0-logs/local-1699608073397.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=94208, output stream=DFSOutputStream:blk_1073742677_1858
23/11/10 17:21:18 DEBUG DFSClient: DFSClient flush():  bytesCurBlock=99386, lastFlushOffset=94652, createNewBlock=false
23/11/10 17:21:18 DEBUG DataStreamer: Queued packet seqno: 10 offsetInBlock: 94208 lastPacketInBlock: false lastByteOffsetInBlock: 99386, blk_1073742677_1858
23/11/10 17:21:18 DEBUG DataStreamer: blk_1073742677_1858 waiting for ack for: 10
23/11/10 17:21:18 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Keep Legacy Outputs after 1 iterations.
23/11/10 17:21:18 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 10 offsetInBlock: 94208 lastPacketInBlock: false lastByteOffsetInBlock: 99386
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Keep Legacy Outputs has no effect.
23/11/10 17:21:18 DEBUG DataStreamer: DFSClient seqno: 10 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:18 TRACE Analyzer$ResolveReferences: Attempting to resolve LocalRelation <empty>, [t_col#4]
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveDeserializer ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StructField(t_col,IntegerType,false)), StructField(t_col,IntegerType,false))), obj#14: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(t_col#4, StructField(t_col,IntegerType,false)), obj#14: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [t_col#4]                                                                                                                                                                   +- LocalRelation <empty>, [t_col#4]
           
23/11/10 17:21:18 TRACE Analyzer$ResolveReferences: Attempting to resolve DeserializeToObject createexternalrow(t_col#4, StructField(t_col,IntegerType,false)), obj#14: org.apache.spark.sql.Row
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Resolution after 2 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StructField(t_col,IntegerType,false)), StructField(t_col,IntegerType,false))), obj#14: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(t_col#4, StructField(t_col,IntegerType,false)), obj#14: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [t_col#4]                                                                                                                                                                   +- LocalRelation <empty>, [t_col#4]
          
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove TempResolvedColumn after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Remove TempResolvedColumn has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Apply Char Padding after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Apply Char Padding has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Post-Hoc Resolution after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Post-Hoc Resolution has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Remove Unresolved Hints after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Remove Unresolved Hints has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Nondeterministic after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Nondeterministic has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UDF after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch UDF has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch UpdateNullability after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch UpdateNullability has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Subquery after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Subquery has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch Cleanup after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch Cleanup has no effect.
23/11/10 17:21:18 TRACE HiveSessionStateBuilder$$anon$1: Fixed point reached for batch HandleAnalysisOnlyCommand after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch HandleAnalysisOnlyCommand has no effect.
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 133
Total time: 0.001554127 seconds
Total number of effective runs: 1
Total time of effective runs: 1.65455E-4 seconds
      
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch AQE Query Stage Optimization has no effect.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch AQE Post Stage Creation has no effect.
23/11/10 17:21:18 DEBUG BroadcastQueryStageExec: Materialize query stage BroadcastQueryStageExec: 0
23/11/10 17:21:18 DEBUG DFSClient: WriteChunk allocating new packet seqno=11, src=/spark3.3.0-logs/local-1699608073397.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=99328, output stream=DFSOutputStream:blk_1073742677_1858
23/11/10 17:21:18 DEBUG DFSClient: DFSClient flush():  bytesCurBlock=101911, lastFlushOffset=99386, createNewBlock=false
23/11/10 17:21:18 DEBUG DataStreamer: Queued packet seqno: 11 offsetInBlock: 99328 lastPacketInBlock: false lastByteOffsetInBlock: 101911, blk_1073742677_1858
23/11/10 17:21:18 DEBUG DataStreamer: blk_1073742677_1858 waiting for ack for: 11
23/11/10 17:21:18 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:18 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 11 offsetInBlock: 99328 lastPacketInBlock: false lastByteOffsetInBlock: 101911
23/11/10 17:21:18 DEBUG DataStreamer: DFSClient seqno: 11 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:18 TRACE package$ExpressionCanonicalizer: Fixed point reached for batch CleanExpressions after 1 iterations.
23/11/10 17:21:18 TRACE PlanChangeLogger: Batch CleanExpressions has no effect.
23/11/10 17:21:18 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 1
Total time: 5.124E-6 seconds
Total number of effective runs: 0
Total time of effective runs: 0.0 seconds
      
23/11/10 17:21:18 DEBUG GenerateUnsafeProjection: code for input[0, int, false]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */     int value_0 = i.getInt(0);
/* 032 */     mutableStateArray_0[0].write(0, value_0);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

23/11/10 17:21:18 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$doExecute$1
23/11/10 17:21:18 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$doExecute$1) is now cleaned +++
23/11/10 17:21:18 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$collect$2
23/11/10 17:21:18 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$collect$2) is now cleaned +++
23/11/10 17:21:18 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$runJob$5
23/11/10 17:21:18 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
23/11/10 17:21:18 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
23/11/10 17:21:18 DEBUG DAGScheduler: eagerlyComputePartitionsForRddAndAncestors for RDD 2 took 0.000421 seconds
23/11/10 17:21:18 DEBUG DAGScheduler: Merging stage rdd profiles: Set()
23/11/10 17:21:18 INFO DAGScheduler: Got job 0 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 3 output partitions
23/11/10 17:21:18 INFO DAGScheduler: Final stage: ResultStage 0 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
23/11/10 17:21:18 INFO DAGScheduler: Parents of final stage: List()
23/11/10 17:21:18 INFO DAGScheduler: Missing parents: List()
23/11/10 17:21:18 DEBUG DAGScheduler: submitStage(ResultStage 0 (name=$anonfun$withThreadLocalCaptured$1 at FutureTask.java:266;jobs=0))
23/11/10 17:21:18 DEBUG DAGScheduler: missing: List()
23/11/10 17:21:18 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
23/11/10 17:21:18 DEBUG DAGScheduler: submitMissingTasks(ResultStage 0)
23/11/10 17:21:18 DEBUG DFSClient: WriteChunk allocating new packet seqno=12, src=/spark3.3.0-logs/local-1699608073397.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=101888, output stream=DFSOutputStream:blk_1073742677_1858
23/11/10 17:21:18 DEBUG DFSClient: DFSClient flush():  bytesCurBlock=106551, lastFlushOffset=101911, createNewBlock=false
23/11/10 17:21:18 DEBUG DataStreamer: Queued packet seqno: 12 offsetInBlock: 101888 lastPacketInBlock: false lastByteOffsetInBlock: 106551, blk_1073742677_1858
23/11/10 17:21:18 DEBUG DataStreamer: blk_1073742677_1858 waiting for ack for: 12
23/11/10 17:21:18 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:18 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 12 offsetInBlock: 101888 lastPacketInBlock: false lastByteOffsetInBlock: 106551
23/11/10 17:21:18 DEBUG DataStreamer: DFSClient seqno: 12 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:18 TRACE BlockInfoManager: Task -1024 trying to put broadcast_0
23/11/10 17:21:18 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_0
23/11/10 17:21:18 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_0
23/11/10 17:21:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.2 KiB, free 366.3 MiB)
23/11/10 17:21:18 DEBUG BlockManager: Put block broadcast_0 locally took 12 ms
23/11/10 17:21:18 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_0
23/11/10 17:21:18 DEBUG BlockManager: Putting block broadcast_0 without replication took 12 ms
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 trying to put broadcast_0_piece0
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_0_piece0
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_0_piece0
23/11/10 17:21:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 366.3 MiB)
23/11/10 17:21:19 DEBUG BlockManagerMasterEndpoint: Updating block info on master broadcast_0_piece0 for BlockManagerId(driver, Jiahao, 37505, None)
23/11/10 17:21:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on Jiahao:37505 (size: 2.9 KiB, free: 366.3 MiB)
23/11/10 17:21:19 DEBUG BlockManagerMaster: Updated info of block broadcast_0_piece0
23/11/10 17:21:19 DEBUG BlockManager: Told master about block broadcast_0_piece0
23/11/10 17:21:19 DEBUG BlockManager: Put block broadcast_0_piece0 locally took 3 ms
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_0_piece0
23/11/10 17:21:19 DEBUG BlockManager: Putting block broadcast_0_piece0 without replication took 3 ms
23/11/10 17:21:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
23/11/10 17:21:19 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1, 2))
23/11/10 17:21:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 3 tasks resource profile 0
23/11/10 17:21:19 DEBUG TaskSetManager: Epoch for TaskSet 0.0: 0
23/11/10 17:21:19 DEBUG TaskSetManager: Adding pending tasks took 0 ms
23/11/10 17:21:19 DEBUG TaskSetManager: Valid locality levels for TaskSet 0.0: NO_PREF, ANY
23/11/10 17:21:19 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0.0, runningTasks: 0
23/11/10 17:21:19 DEBUG TaskSetManager: Valid locality levels for TaskSet 0.0: NO_PREF, ANY
23/11/10 17:21:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (Jiahao, executor driver, partition 0, PROCESS_LOCAL, 4625 bytes) taskResourceAssignments Map()
23/11/10 17:21:19 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (Jiahao, executor driver, partition 1, PROCESS_LOCAL, 4625 bytes) taskResourceAssignments Map()
23/11/10 17:21:19 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (Jiahao, executor driver, partition 2, PROCESS_LOCAL, 4625 bytes) taskResourceAssignments Map()
23/11/10 17:21:19 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
23/11/10 17:21:19 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
23/11/10 17:21:19 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/11/10 17:21:19 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
23/11/10 17:21:19 DEBUG ExecutorMetricsPoller: stageTCMP: (0, 0) -> 3
23/11/10 17:21:19 DEBUG ExecutorMetricsPoller: stageTCMP: (0, 0) -> 1
23/11/10 17:21:19 DEBUG ExecutorMetricsPoller: stageTCMP: (0, 0) -> 2
23/11/10 17:21:19 DEBUG BlockManager: Getting local block broadcast_0
23/11/10 17:21:19 TRACE BlockInfoManager: Task 1 trying to acquire read lock for broadcast_0
23/11/10 17:21:19 TRACE BlockInfoManager: Task 1 acquired read lock for broadcast_0
23/11/10 17:21:19 DEBUG BlockManager: Level for block broadcast_0 is StorageLevel(disk, memory, deserialized, 1 replicas)
23/11/10 17:21:19 TRACE BlockInfoManager: Task 1 releasing lock for broadcast_0
23/11/10 17:21:19 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1382 bytes result sent to driver
23/11/10 17:21:19 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1382 bytes result sent to driver
23/11/10 17:21:19 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1382 bytes result sent to driver
23/11/10 17:21:19 DEBUG ExecutorMetricsPoller: stageTCMP: (0, 0) -> 2
23/11/10 17:21:19 DEBUG ExecutorMetricsPoller: stageTCMP: (0, 0) -> 1
23/11/10 17:21:19 DEBUG ExecutorMetricsPoller: stageTCMP: (0, 0) -> 0
23/11/10 17:21:19 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 177 ms on Jiahao (executor driver) (1/3)
23/11/10 17:21:19 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 179 ms on Jiahao (executor driver) (2/3)
23/11/10 17:21:19 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 193 ms on Jiahao (executor driver) (3/3)
23/11/10 17:21:19 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/11/10 17:21:19 INFO DAGScheduler: ResultStage 0 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.279 s
23/11/10 17:21:19 DEBUG DAGScheduler: After removal of stage 0, remaining stages = 0
23/11/10 17:21:19 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/10 17:21:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/11/10 17:21:19 INFO DAGScheduler: Job 0 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.301855 s
23/11/10 17:21:19 DEBUG DFSClient: WriteChunk allocating new packet seqno=13, src=/spark3.3.0-logs/local-1699608073397.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=106496, output stream=DFSOutputStream:blk_1073742677_1858
23/11/10 17:21:19 DEBUG DFSClient: DFSClient flush():  bytesCurBlock=122356, lastFlushOffset=106551, createNewBlock=false
23/11/10 17:21:19 DEBUG DataStreamer: Queued packet seqno: 13 offsetInBlock: 106496 lastPacketInBlock: false lastByteOffsetInBlock: 122356, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 waiting for ack for: 13
23/11/10 17:21:19 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 13 offsetInBlock: 106496 lastPacketInBlock: false lastByteOffsetInBlock: 122356
23/11/10 17:21:19 DEBUG DataStreamer: DFSClient seqno: 13 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:19 DEBUG DFSClient: WriteChunk allocating new packet seqno=14, src=/spark3.3.0-logs/local-1699608073397.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=121856, output stream=DFSOutputStream:blk_1073742677_1858
23/11/10 17:21:19 DEBUG DFSClient: DFSClient flush():  bytesCurBlock=122470, lastFlushOffset=122356, createNewBlock=false
23/11/10 17:21:19 DEBUG DataStreamer: Queued packet seqno: 14 offsetInBlock: 121856 lastPacketInBlock: false lastByteOffsetInBlock: 122470, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 waiting for ack for: 14
23/11/10 17:21:19 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 14 offsetInBlock: 121856 lastPacketInBlock: false lastByteOffsetInBlock: 122470
23/11/10 17:21:19 DEBUG DataStreamer: DFSClient seqno: 14 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:19 DEBUG TaskMemoryManager: Task 0 acquired 1024.1 KiB for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@bf0dfa4
23/11/10 17:21:19 TRACE package$ExpressionCanonicalizer: Fixed point reached for batch CleanExpressions after 1 iterations.
23/11/10 17:21:19 TRACE PlanChangeLogger: Batch CleanExpressions has no effect.
23/11/10 17:21:19 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 1
Total time: 1.0235E-5 seconds
Total number of effective runs: 0
Total time of effective runs: 0.0 seconds
      
23/11/10 17:21:19 DEBUG GenerateUnsafeProjection: code for cast(input[0, int, false] as bigint):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     int value_1 = i.getInt(0);
/* 032 */     boolean isNull_0 = false;
/* 033 */     long value_0 = -1L;
/* 034 */     if (!false) {
/* 035 */       value_0 = (long) value_1;
/* 036 */     }
/* 037 */     mutableStateArray_0[0].write(0, value_0);
/* 038 */     return (mutableStateArray_0[0].getRow());
/* 039 */   }
/* 040 */
/* 041 */
/* 042 */ }

23/11/10 17:21:19 DEBUG CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     int value_1 = i.getInt(0);
/* 032 */     boolean isNull_0 = false;
/* 033 */     long value_0 = -1L;
/* 034 */     if (!false) {
/* 035 */       value_0 = (long) value_1;
/* 036 */     }
/* 037 */     mutableStateArray_0[0].write(0, value_0);
/* 038 */     return (mutableStateArray_0[0].getRow());
/* 039 */   }
/* 040 */
/* 041 */
/* 042 */ }

23/11/10 17:21:19 INFO CodeGenerator: Code generated in 11.096177 ms
23/11/10 17:21:19 DEBUG TaskMemoryManager: Task 0 acquired 128.0 B for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@bf0dfa4
23/11/10 17:21:19 DEBUG TaskMemoryManager: Task 0 release 64.0 B from org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@bf0dfa4
23/11/10 17:21:19 DEBUG TaskMemoryManager: Task 0 acquired 24.0 B for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@bf0dfa4
23/11/10 17:21:19 DEBUG TaskMemoryManager: Task 0 release 128.0 B from org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@bf0dfa4
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 trying to put broadcast_1
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_1
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_1
23/11/10 17:21:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1024.0 KiB, free 365.3 MiB)
23/11/10 17:21:19 DEBUG BlockManager: Put block broadcast_1 locally took 0 ms
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_1
23/11/10 17:21:19 DEBUG BlockManager: Putting block broadcast_1 without replication took 0 ms
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 trying to put broadcast_1_piece0
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_1_piece0
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_1_piece0
23/11/10 17:21:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 231.0 B, free 365.3 MiB)
23/11/10 17:21:19 DEBUG BlockManagerMasterEndpoint: Updating block info on master broadcast_1_piece0 for BlockManagerId(driver, Jiahao, 37505, None)
23/11/10 17:21:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on Jiahao:37505 (size: 231.0 B, free: 366.3 MiB)
23/11/10 17:21:19 DEBUG BlockManagerMaster: Updated info of block broadcast_1_piece0
23/11/10 17:21:19 DEBUG BlockManager: Told master about block broadcast_1_piece0
23/11/10 17:21:19 DEBUG BlockManager: Put block broadcast_1_piece0 locally took 0 ms
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_1_piece0
23/11/10 17:21:19 DEBUG BlockManager: Putting block broadcast_1_piece0 without replication took 0 ms
23/11/10 17:21:19 INFO SparkContext: Created broadcast 1 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
23/11/10 17:21:19 DEBUG DFSClient: WriteChunk allocating new packet seqno=15, src=/spark3.3.0-logs/local-1699608073397.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=122368, output stream=DFSOutputStream:blk_1073742677_1858
23/11/10 17:21:19 DEBUG DFSClient: DFSClient flush():  bytesCurBlock=122620, lastFlushOffset=122470, createNewBlock=false
23/11/10 17:21:19 DEBUG DataStreamer: Queued packet seqno: 15 offsetInBlock: 122368 lastPacketInBlock: false lastByteOffsetInBlock: 122620, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 waiting for ack for: 15
23/11/10 17:21:19 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 15 offsetInBlock: 122368 lastPacketInBlock: false lastByteOffsetInBlock: 122620
23/11/10 17:21:19 DEBUG DataStreamer: DFSClient seqno: 15 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:19 TRACE AQEOptimizer: Fixed point reached for batch Propagate Empty Relations after 1 iterations.
23/11/10 17:21:19 TRACE PlanChangeLogger: Batch Propagate Empty Relations has no effect.
23/11/10 17:21:19 DEBUG ExtractEquiJoinKeys: Considering join on: Some((t_col#4 = s_col#10))
23/11/10 17:21:19 DEBUG ExtractEquiJoinKeys: leftKeys:List(t_col#4) | rightKeys:List(s_col#10)
23/11/10 17:21:19 TRACE AQEOptimizer: Fixed point reached for batch Dynamic Join Selection after 1 iterations.
23/11/10 17:21:19 TRACE PlanChangeLogger: Batch Dynamic Join Selection has no effect.
23/11/10 17:21:19 TRACE AQEOptimizer: Fixed point reached for batch Eliminate Limits after 1 iterations.
23/11/10 17:21:19 TRACE PlanChangeLogger: Batch Eliminate Limits has no effect.
23/11/10 17:21:19 TRACE AQEOptimizer: Fixed point reached for batch Optimize One Row Plan after 1 iterations.
23/11/10 17:21:19 TRACE PlanChangeLogger: Batch Optimize One Row Plan has no effect.
23/11/10 17:21:19 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 6
Total time: 0.002424362 seconds
Total number of effective runs: 0
Total time of effective runs: 0.0 seconds
      
23/11/10 17:21:19 DEBUG ExtractEquiJoinKeys: Considering join on: Some((t_col#4 = s_col#10))
23/11/10 17:21:19 DEBUG ExtractEquiJoinKeys: leftKeys:List(t_col#4) | rightKeys:List(s_col#10)
23/11/10 17:21:19 TRACE PlanChangeLogger: Batch AQE Replanning has no effect.
23/11/10 17:21:19 TRACE PlanChangeLogger: Batch AQE Query Stage Optimization has no effect.
23/11/10 17:21:19 TRACE PlanChangeLogger: 
=== Applying Rule org.apache.spark.sql.execution.CollapseCodegenStages ===
!BroadcastHashJoin [t_col#4], [s_col#10], LeftSemi, BuildRight, false                                              *(1) BroadcastHashJoin [t_col#4], [s_col#10], LeftSemi, BuildRight, false
!:- LocalTableScan [t_col#4]                                                                                       :- *(1) LocalTableScan [t_col#4]
 +- BroadcastQueryStage 0                                                                                          +- BroadcastQueryStage 0
    +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#18]      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#18]
       +- LocalTableScan [s_col#10]                                                                                      +- LocalTableScan [s_col#10]
           
23/11/10 17:21:19 TRACE PlanChangeLogger: 
=== Result of Batch AQE Post Stage Creation ===
!BroadcastHashJoin [t_col#4], [s_col#10], LeftSemi, BuildRight, false                                              *(1) BroadcastHashJoin [t_col#4], [s_col#10], LeftSemi, BuildRight, false
!:- LocalTableScan [t_col#4]                                                                                       :- *(1) LocalTableScan [t_col#4]
 +- BroadcastQueryStage 0                                                                                          +- BroadcastQueryStage 0
    +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#18]      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#18]
       +- LocalTableScan [s_col#10]                                                                                      +- LocalTableScan [s_col#10]
          
23/11/10 17:21:19 DEBUG DFSClient: WriteChunk allocating new packet seqno=16, src=/spark3.3.0-logs/local-1699608073397.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=122368, output stream=DFSOutputStream:blk_1073742677_1858
23/11/10 17:21:19 DEBUG DFSClient: DFSClient flush():  bytesCurBlock=125502, lastFlushOffset=122620, createNewBlock=false
23/11/10 17:21:19 DEBUG DataStreamer: Queued packet seqno: 16 offsetInBlock: 122368 lastPacketInBlock: false lastByteOffsetInBlock: 125502, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 waiting for ack for: 16
23/11/10 17:21:19 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 16 offsetInBlock: 122368 lastPacketInBlock: false lastByteOffsetInBlock: 125502
23/11/10 17:21:19 DEBUG DataStreamer: DFSClient seqno: 16 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:19 DEBUG BlockManager: Getting local block broadcast_1
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 trying to acquire read lock for broadcast_1
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 acquired read lock for broadcast_1
23/11/10 17:21:19 DEBUG BlockManager: Level for block broadcast_1 is StorageLevel(disk, memory, deserialized, 1 replicas)
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_1
23/11/10 17:21:19 DEBUG WholeStageCodegenExec: 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator localtablescan_input_0;
/* 010 */   private org.apache.spark.sql.execution.joins.LongHashedRelation bhj_relation_0;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] bhj_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 012 */
/* 013 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 018 */     partitionIndex = index;
/* 019 */     this.inputs = inputs;
/* 020 */     localtablescan_input_0 = inputs[0];
/* 021 */
/* 022 */     bhj_relation_0 = ((org.apache.spark.sql.execution.joins.LongHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[1] /* broadcast */).value()).asReadOnlyCopy();
/* 023 */     incPeakExecutionMemory(bhj_relation_0.estimatedSize());
/* 024 */
/* 025 */     bhj_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 026 */
/* 027 */   }
/* 028 */
/* 029 */   private void bhj_doConsume_0(InternalRow localtablescan_row_0, int bhj_expr_0_0) throws java.io.IOException {
/* 030 */     // generate join key for stream side
/* 031 */     boolean bhj_isNull_0 = false;
/* 032 */     long bhj_value_0 = -1L;
/* 033 */     if (!false) {
/* 034 */       bhj_value_0 = (long) bhj_expr_0_0;
/* 035 */     }
/* 036 */     // find matches from HashedRelation
/* 037 */     UnsafeRow bhj_buildRow_0 = bhj_isNull_0 ? null: (UnsafeRow)bhj_relation_0.getValue(bhj_value_0);
/* 038 */     if (bhj_buildRow_0 != null) {
/* 039 */       {
/* 040 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[2] /* numOutputRows */).add(1);
/* 041 */
/* 042 */         bhj_mutableStateArray_0[0].reset();
/* 043 */
/* 044 */         bhj_mutableStateArray_0[0].write(0, bhj_expr_0_0);
/* 045 */         append((bhj_mutableStateArray_0[0].getRow()));
/* 046 */
/* 047 */       }
/* 048 */     }
/* 049 */
/* 050 */   }
/* 051 */
/* 052 */   protected void processNext() throws java.io.IOException {
/* 053 */     while ( localtablescan_input_0.hasNext()) {
/* 054 */       InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();
/* 055 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 056 */       int localtablescan_value_0 = localtablescan_row_0.getInt(0);
/* 057 */
/* 058 */       bhj_doConsume_0(localtablescan_row_0, localtablescan_value_0);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */
/* 063 */ }

23/11/10 17:21:19 DEBUG CodeGenerator: 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator localtablescan_input_0;
/* 010 */   private org.apache.spark.sql.execution.joins.LongHashedRelation bhj_relation_0;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] bhj_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 012 */
/* 013 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 018 */     partitionIndex = index;
/* 019 */     this.inputs = inputs;
/* 020 */     localtablescan_input_0 = inputs[0];
/* 021 */
/* 022 */     bhj_relation_0 = ((org.apache.spark.sql.execution.joins.LongHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[1] /* broadcast */).value()).asReadOnlyCopy();
/* 023 */     incPeakExecutionMemory(bhj_relation_0.estimatedSize());
/* 024 */
/* 025 */     bhj_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 026 */
/* 027 */   }
/* 028 */
/* 029 */   private void bhj_doConsume_0(InternalRow localtablescan_row_0, int bhj_expr_0_0) throws java.io.IOException {
/* 030 */     // generate join key for stream side
/* 031 */     boolean bhj_isNull_0 = false;
/* 032 */     long bhj_value_0 = -1L;
/* 033 */     if (!false) {
/* 034 */       bhj_value_0 = (long) bhj_expr_0_0;
/* 035 */     }
/* 036 */     // find matches from HashedRelation
/* 037 */     UnsafeRow bhj_buildRow_0 = bhj_isNull_0 ? null: (UnsafeRow)bhj_relation_0.getValue(bhj_value_0);
/* 038 */     if (bhj_buildRow_0 != null) {
/* 039 */       {
/* 040 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[2] /* numOutputRows */).add(1);
/* 041 */
/* 042 */         bhj_mutableStateArray_0[0].reset();
/* 043 */
/* 044 */         bhj_mutableStateArray_0[0].write(0, bhj_expr_0_0);
/* 045 */         append((bhj_mutableStateArray_0[0].getRow()));
/* 046 */
/* 047 */       }
/* 048 */     }
/* 049 */
/* 050 */   }
/* 051 */
/* 052 */   protected void processNext() throws java.io.IOException {
/* 053 */     while ( localtablescan_input_0.hasNext()) {
/* 054 */       InternalRow localtablescan_row_0 = (InternalRow) localtablescan_input_0.next();
/* 055 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 056 */       int localtablescan_value_0 = localtablescan_row_0.getInt(0);
/* 057 */
/* 058 */       bhj_doConsume_0(localtablescan_row_0, localtablescan_value_0);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */
/* 063 */ }

23/11/10 17:21:19 INFO CodeGenerator: Code generated in 11.963154 ms
23/11/10 17:21:19 TRACE package$ExpressionCanonicalizer: Fixed point reached for batch CleanExpressions after 1 iterations.
23/11/10 17:21:19 TRACE PlanChangeLogger: Batch CleanExpressions has no effect.
23/11/10 17:21:19 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 1
Total time: 3.823E-6 seconds
Total number of effective runs: 0
Total time of effective runs: 0.0 seconds
      
23/11/10 17:21:19 DEBUG GenerateUnsafeProjection: code for input[0, int, false]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */     int value_0 = i.getInt(0);
/* 032 */     mutableStateArray_0[0].write(0, value_0);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

23/11/10 17:21:19 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$doExecute$4$adapted
23/11/10 17:21:19 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
23/11/10 17:21:19 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$collect$2
23/11/10 17:21:19 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$collect$2) is now cleaned +++
23/11/10 17:21:19 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$runJob$5
23/11/10 17:21:19 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
23/11/10 17:21:19 INFO SparkContext: Starting job: collect at /home/dbgroup/Documents/Code/Research/qotrace/qotrace-misc/spark-program/spark-scripts/bug4-0/Bug4_0.scala:38
23/11/10 17:21:19 DEBUG DAGScheduler: eagerlyComputePartitionsForRddAndAncestors for RDD 5 took 0.000041 seconds
23/11/10 17:21:19 DEBUG DAGScheduler: Merging stage rdd profiles: Set()
23/11/10 17:21:19 INFO DAGScheduler: Got job 1 (collect at /home/dbgroup/Documents/Code/Research/qotrace/qotrace-misc/spark-program/spark-scripts/bug4-0/Bug4_0.scala:38) with 3 output partitions
23/11/10 17:21:19 INFO DAGScheduler: Final stage: ResultStage 1 (collect at /home/dbgroup/Documents/Code/Research/qotrace/qotrace-misc/spark-program/spark-scripts/bug4-0/Bug4_0.scala:38)
23/11/10 17:21:19 INFO DAGScheduler: Parents of final stage: List()
23/11/10 17:21:19 INFO DAGScheduler: Missing parents: List()
23/11/10 17:21:19 DEBUG DAGScheduler: submitStage(ResultStage 1 (name=collect at /home/dbgroup/Documents/Code/Research/qotrace/qotrace-misc/spark-program/spark-scripts/bug4-0/Bug4_0.scala:38;jobs=1))
23/11/10 17:21:19 DEBUG DAGScheduler: missing: List()
23/11/10 17:21:19 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at /home/dbgroup/Documents/Code/Research/qotrace/qotrace-misc/spark-program/spark-scripts/bug4-0/Bug4_0.scala:38), which has no missing parents
23/11/10 17:21:19 DEBUG DAGScheduler: submitMissingTasks(ResultStage 1)
23/11/10 17:21:19 DEBUG DFSClient: WriteChunk allocating new packet seqno=17, src=/spark3.3.0-logs/local-1699608073397.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=125440, output stream=DFSOutputStream:blk_1073742677_1858
23/11/10 17:21:19 DEBUG DFSClient: DFSClient flush():  bytesCurBlock=132375, lastFlushOffset=125502, createNewBlock=false
23/11/10 17:21:19 DEBUG DataStreamer: Queued packet seqno: 17 offsetInBlock: 125440 lastPacketInBlock: false lastByteOffsetInBlock: 132375, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 waiting for ack for: 17
23/11/10 17:21:19 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 17 offsetInBlock: 125440 lastPacketInBlock: false lastByteOffsetInBlock: 132375
23/11/10 17:21:19 DEBUG DataStreamer: DFSClient seqno: 17 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 trying to put broadcast_2
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_2
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_2
23/11/10 17:21:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.8 KiB, free 365.3 MiB)
23/11/10 17:21:19 DEBUG BlockManager: Put block broadcast_2 locally took 0 ms
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_2
23/11/10 17:21:19 DEBUG BlockManager: Putting block broadcast_2 without replication took 0 ms
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 trying to put broadcast_2_piece0
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 trying to acquire write lock for broadcast_2_piece0
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 acquired write lock for broadcast_2_piece0
23/11/10 17:21:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 365.3 MiB)
23/11/10 17:21:19 DEBUG BlockManagerMasterEndpoint: Updating block info on master broadcast_2_piece0 for BlockManagerId(driver, Jiahao, 37505, None)
23/11/10 17:21:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on Jiahao:37505 (size: 4.5 KiB, free: 366.3 MiB)
23/11/10 17:21:19 DEBUG BlockManagerMaster: Updated info of block broadcast_2_piece0
23/11/10 17:21:19 DEBUG BlockManager: Told master about block broadcast_2_piece0
23/11/10 17:21:19 DEBUG BlockManager: Put block broadcast_2_piece0 locally took 0 ms
23/11/10 17:21:19 TRACE BlockInfoManager: Task -1024 releasing lock for broadcast_2_piece0
23/11/10 17:21:19 DEBUG BlockManager: Putting block broadcast_2_piece0 without replication took 0 ms
23/11/10 17:21:19 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1513
23/11/10 17:21:19 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at /home/dbgroup/Documents/Code/Research/qotrace/qotrace-misc/spark-program/spark-scripts/bug4-0/Bug4_0.scala:38) (first 15 tasks are for partitions Vector(0, 1, 2))
23/11/10 17:21:19 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks resource profile 0
23/11/10 17:21:19 DEBUG TaskSetManager: Epoch for TaskSet 1.0: 0
23/11/10 17:21:19 DEBUG TaskSetManager: Adding pending tasks took 0 ms
23/11/10 17:21:19 DEBUG TaskSetManager: Valid locality levels for TaskSet 1.0: NO_PREF, ANY
23/11/10 17:21:19 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_1.0, runningTasks: 0
23/11/10 17:21:19 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 3) (Jiahao, executor driver, partition 0, PROCESS_LOCAL, 4625 bytes) taskResourceAssignments Map()
23/11/10 17:21:19 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 4) (Jiahao, executor driver, partition 1, PROCESS_LOCAL, 4625 bytes) taskResourceAssignments Map()
23/11/10 17:21:19 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 5) (Jiahao, executor driver, partition 2, PROCESS_LOCAL, 4625 bytes) taskResourceAssignments Map()
23/11/10 17:21:19 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
23/11/10 17:21:19 INFO Executor: Running task 0.0 in stage 1.0 (TID 3)
23/11/10 17:21:19 INFO Executor: Running task 1.0 in stage 1.0 (TID 4)
23/11/10 17:21:19 INFO Executor: Running task 2.0 in stage 1.0 (TID 5)
23/11/10 17:21:19 DEBUG ExecutorMetricsPoller: stageTCMP: (1, 0) -> 1
23/11/10 17:21:19 DEBUG ExecutorMetricsPoller: stageTCMP: (1, 0) -> 2
23/11/10 17:21:19 DEBUG ExecutorMetricsPoller: stageTCMP: (1, 0) -> 3
23/11/10 17:21:19 DEBUG BlockManager: Getting local block broadcast_2
23/11/10 17:21:19 TRACE BlockInfoManager: Task 5 trying to acquire read lock for broadcast_2
23/11/10 17:21:19 TRACE BlockInfoManager: Task 5 acquired read lock for broadcast_2
23/11/10 17:21:19 DEBUG BlockManager: Level for block broadcast_2 is StorageLevel(disk, memory, deserialized, 1 replicas)
23/11/10 17:21:19 TRACE BlockInfoManager: Task 5 releasing lock for broadcast_2
23/11/10 17:21:19 INFO Executor: Finished task 2.0 in stage 1.0 (TID 5). 1510 bytes result sent to driver
23/11/10 17:21:19 INFO Executor: Finished task 0.0 in stage 1.0 (TID 3). 1493 bytes result sent to driver
23/11/10 17:21:19 DEBUG ExecutorMetricsPoller: stageTCMP: (1, 0) -> 2
23/11/10 17:21:19 DEBUG ExecutorMetricsPoller: stageTCMP: (1, 0) -> 1
23/11/10 17:21:19 INFO Executor: Finished task 1.0 in stage 1.0 (TID 4). 1510 bytes result sent to driver
23/11/10 17:21:19 DEBUG ExecutorMetricsPoller: stageTCMP: (1, 0) -> 0
23/11/10 17:21:19 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 5) in 10 ms on Jiahao (executor driver) (1/3)
23/11/10 17:21:19 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 3) in 11 ms on Jiahao (executor driver) (2/3)
23/11/10 17:21:19 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 4) in 10 ms on Jiahao (executor driver) (3/3)
23/11/10 17:21:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/11/10 17:21:19 DEBUG DFSClient: WriteChunk allocating new packet seqno=18, src=/spark3.3.0-logs/local-1699608073397.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=132096, output stream=DFSOutputStream:blk_1073742677_1858
23/11/10 17:21:19 INFO DAGScheduler: ResultStage 1 (collect at /home/dbgroup/Documents/Code/Research/qotrace/qotrace-misc/spark-program/spark-scripts/bug4-0/Bug4_0.scala:38) finished in 0.016 s
23/11/10 17:21:19 DEBUG DAGScheduler: After removal of stage 1, remaining stages = 0
23/11/10 17:21:19 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/10 17:21:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
23/11/10 17:21:19 INFO DAGScheduler: Job 1 finished: collect at /home/dbgroup/Documents/Code/Research/qotrace/qotrace-misc/spark-program/spark-scripts/bug4-0/Bug4_0.scala:38, took 0.017531 s
23/11/10 17:21:19 DEBUG DFSClient: DFSClient flush():  bytesCurBlock=153692, lastFlushOffset=132375, createNewBlock=false
23/11/10 17:21:19 DEBUG DataStreamer: Queued packet seqno: 18 offsetInBlock: 132096 lastPacketInBlock: false lastByteOffsetInBlock: 153692, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 waiting for ack for: 18
23/11/10 17:21:19 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 18 offsetInBlock: 132096 lastPacketInBlock: false lastByteOffsetInBlock: 153692
23/11/10 17:21:19 DEBUG DataStreamer: DFSClient seqno: 18 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:19 DEBUG DFSClient: WriteChunk allocating new packet seqno=19, src=/spark3.3.0-logs/local-1699608073397.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=153600, output stream=DFSOutputStream:blk_1073742677_1858
23/11/10 17:21:19 DEBUG DFSClient: DFSClient flush():  bytesCurBlock=153806, lastFlushOffset=153692, createNewBlock=false
23/11/10 17:21:19 DEBUG DataStreamer: Queued packet seqno: 19 offsetInBlock: 153600 lastPacketInBlock: false lastByteOffsetInBlock: 153806, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 waiting for ack for: 19
23/11/10 17:21:19 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 19 offsetInBlock: 153600 lastPacketInBlock: false lastByteOffsetInBlock: 153806
23/11/10 17:21:19 DEBUG AdaptiveSparkPlanExec: Final plan: *(1) BroadcastHashJoin [t_col#4], [s_col#10], LeftSemi, BuildRight, false
:- *(1) LocalTableScan [t_col#4]
+- BroadcastQueryStage 0
   +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#18]
      +- LocalTableScan [s_col#10]

23/11/10 17:21:19 DEBUG DataStreamer: DFSClient seqno: 19 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:19 TRACE package$ExpressionCanonicalizer: Fixed point reached for batch CleanExpressions after 1 iterations.
23/11/10 17:21:19 TRACE PlanChangeLogger: Batch CleanExpressions has no effect.
23/11/10 17:21:19 TRACE PlanChangeLogger: 
=== Metrics of Executed Rules ===
Total number of runs: 1
Total time: 1.2339E-5 seconds
Total number of effective runs: 0
Total time of effective runs: 0.0 seconds
      
23/11/10 17:21:19 DEBUG GenerateSafeProjection: code for createexternalrow(input[0, int, false], StructField(t_col,IntegerType,false)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     Object[] values_0 = new Object[1];
/* 024 */
/* 025 */     int value_1 = i.getInt(0);
/* 026 */     if (false) {
/* 027 */       values_0[0] = null;
/* 028 */     } else {
/* 029 */       values_0[0] = value_1;
/* 030 */     }
/* 031 */
/* 032 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 033 */     if (false) {
/* 034 */       mutableRow.setNullAt(0);
/* 035 */     } else {
/* 036 */
/* 037 */       mutableRow.update(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     return mutableRow;
/* 041 */   }
/* 042 */
/* 043 */
/* 044 */ }

23/11/10 17:21:19 DEBUG CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     Object[] values_0 = new Object[1];
/* 024 */
/* 025 */     int value_1 = i.getInt(0);
/* 026 */     if (false) {
/* 027 */       values_0[0] = null;
/* 028 */     } else {
/* 029 */       values_0[0] = value_1;
/* 030 */     }
/* 031 */
/* 032 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 033 */     if (false) {
/* 034 */       mutableRow.setNullAt(0);
/* 035 */     } else {
/* 036 */
/* 037 */       mutableRow.update(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     return mutableRow;
/* 041 */   }
/* 042 */
/* 043 */
/* 044 */ }

23/11/10 17:21:19 INFO CodeGenerator: Code generated in 6.412389 ms
Completed
[END] Time = 3.846 s
23/11/10 17:21:19 DEBUG DFSClient: WriteChunk allocating new packet seqno=20, src=/spark3.3.0-logs/local-1699608073397.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=153600, output stream=DFSOutputStream:blk_1073742677_1858
23/11/10 17:21:19 DEBUG DFSClient: DFSClient flush():  bytesCurBlock=153918, lastFlushOffset=153806, createNewBlock=false
23/11/10 17:21:19 DEBUG DataStreamer: Queued packet seqno: 20 offsetInBlock: 153600 lastPacketInBlock: false lastByteOffsetInBlock: 153918, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 waiting for ack for: 20
23/11/10 17:21:19 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 20 offsetInBlock: 153600 lastPacketInBlock: false lastByteOffsetInBlock: 153918
23/11/10 17:21:19 DEBUG DataStreamer: DFSClient seqno: 20 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:19 INFO SparkContext: Invoking stop() from shutdown hook
23/11/10 17:21:19 DEBUG DFSClient: WriteChunk allocating new packet seqno=21, src=/spark3.3.0-logs/local-1699608073397.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=153600, output stream=DFSOutputStream:blk_1073742677_1858
23/11/10 17:21:19 DEBUG DFSClient: DFSClient flush():  bytesCurBlock=153984, lastFlushOffset=153918, createNewBlock=false
23/11/10 17:21:19 DEBUG DataStreamer: Queued packet seqno: 21 offsetInBlock: 153600 lastPacketInBlock: false lastByteOffsetInBlock: 153984, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 waiting for ack for: 21
23/11/10 17:21:19 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 21 offsetInBlock: 153600 lastPacketInBlock: false lastByteOffsetInBlock: 153984
23/11/10 17:21:19 DEBUG DataStreamer: DFSClient seqno: 21 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:19 INFO SparkUI: Stopped Spark web UI at http://Jiahao:4040
23/11/10 17:21:19 DEBUG DFSClient: WriteChunk allocating new packet seqno=22, src=/spark3.3.0-logs/local-1699608073397.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=153600, output stream=DFSOutputStream:blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: Queued packet seqno: 22 offsetInBlock: 153600 lastPacketInBlock: false lastByteOffsetInBlock: 153984, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: Queued packet seqno: 23 offsetInBlock: 153984 lastPacketInBlock: true lastByteOffsetInBlock: 153984, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 waiting for ack for: 23
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 22 offsetInBlock: 153600 lastPacketInBlock: false lastByteOffsetInBlock: 153984
23/11/10 17:21:19 DEBUG DataStreamer: stage=DATA_STREAMING, blk_1073742677_1858
23/11/10 17:21:19 DEBUG DataStreamer: DFSClient seqno: 22 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:19 DEBUG DataStreamer: blk_1073742677_1858 sending packet seqno: 23 offsetInBlock: 153984 lastPacketInBlock: true lastByteOffsetInBlock: 153984
23/11/10 17:21:19 DEBUG DataStreamer: DFSClient seqno: 23 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
23/11/10 17:21:19 DEBUG DataStreamer: Closing old block BP-80912574-127.0.1.1-1665050837178:blk_1073742677_1858
23/11/10 17:21:19 TRACE ProtobufRpcEngine2: 101: Call -> Jiahao/127.0.1.1:9000: complete {src: "/spark3.3.0-logs/local-1699608073397.inprogress" clientName: "DFSClient_NONMAPREDUCE_1188829182_1" last { poolId: "BP-80912574-127.0.1.1-1665050837178" blockId: 1073742677 generationStamp: 1858 numBytes: 153984 } fileId: 17317}
23/11/10 17:21:19 DEBUG Client: IPC Client (1660295258) connection to Jiahao/127.0.1.1:9000 from dbgroup sending #7 org.apache.hadoop.hdfs.protocol.ClientProtocol.complete
23/11/10 17:21:19 DEBUG Client: IPC Client (1660295258) connection to Jiahao/127.0.1.1:9000 from dbgroup got value #7
23/11/10 17:21:19 DEBUG ProtobufRpcEngine2: Call: complete took 1ms
23/11/10 17:21:19 TRACE ProtobufRpcEngine2: 101: Response <- Jiahao/127.0.1.1:9000: complete {result: true}
23/11/10 17:21:19 TRACE ProtobufRpcEngine2: 101: Call -> Jiahao/127.0.1.1:9000: getFileInfo {src: "/spark3.3.0-logs/local-1699608073397"}
23/11/10 17:21:19 DEBUG Client: IPC Client (1660295258) connection to Jiahao/127.0.1.1:9000 from dbgroup sending #8 org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo
23/11/10 17:21:19 DEBUG Client: IPC Client (1660295258) connection to Jiahao/127.0.1.1:9000 from dbgroup got value #8
23/11/10 17:21:19 DEBUG ProtobufRpcEngine2: Call: getFileInfo took 0ms
23/11/10 17:21:19 TRACE ProtobufRpcEngine2: 101: Response <- Jiahao/127.0.1.1:9000: getFileInfo {}
23/11/10 17:21:19 TRACE ProtobufRpcEngine2: 101: Call -> Jiahao/127.0.1.1:9000: rename {src: "/spark3.3.0-logs/local-1699608073397.inprogress" dst: "/spark3.3.0-logs/local-1699608073397"}
23/11/10 17:21:19 DEBUG Client: IPC Client (1660295258) connection to Jiahao/127.0.1.1:9000 from dbgroup sending #9 org.apache.hadoop.hdfs.protocol.ClientProtocol.rename
23/11/10 17:21:19 DEBUG Client: IPC Client (1660295258) connection to Jiahao/127.0.1.1:9000 from dbgroup got value #9
23/11/10 17:21:19 DEBUG ProtobufRpcEngine2: Call: rename took 2ms
23/11/10 17:21:19 TRACE ProtobufRpcEngine2: 101: Response <- Jiahao/127.0.1.1:9000: rename {result: true}
23/11/10 17:21:19 TRACE ProtobufRpcEngine2: 101: Call -> Jiahao/127.0.1.1:9000: setTimes {src: "/spark3.3.0-logs/local-1699608073397" mtime: 1699608079424 atime: 18446744073709551615}
23/11/10 17:21:19 DEBUG Client: IPC Client (1660295258) connection to Jiahao/127.0.1.1:9000 from dbgroup sending #10 org.apache.hadoop.hdfs.protocol.ClientProtocol.setTimes
23/11/10 17:21:19 DEBUG Client: IPC Client (1660295258) connection to Jiahao/127.0.1.1:9000 from dbgroup got value #10
23/11/10 17:21:19 DEBUG ProtobufRpcEngine2: Call: setTimes took 1ms
23/11/10 17:21:19 TRACE ProtobufRpcEngine2: 101: Response <- Jiahao/127.0.1.1:9000: setTimes {}
23/11/10 17:21:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/11/10 17:21:19 INFO MemoryStore: MemoryStore cleared
23/11/10 17:21:19 INFO BlockManager: BlockManager stopped
23/11/10 17:21:19 INFO BlockManagerMaster: BlockManagerMaster stopped
23/11/10 17:21:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/11/10 17:21:19 INFO SparkContext: Successfully stopped SparkContext
23/11/10 17:21:19 INFO ShutdownHookManager: Shutdown hook called
23/11/10 17:21:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-e11abb2e-9081-4ad4-b096-5a2c0152cebb
23/11/10 17:21:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-5ab950c8-dfa4-414c-b15f-638019ca15e5
23/11/10 17:21:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-5ab950c8-dfa4-414c-b15f-638019ca15e5/repl-f1a650ef-e549-438e-8b3e-a590117a8263
23/11/10 17:21:19 DEBUG FileSystem: FileSystem.close() by method: org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:1518)); Key: (dbgroup (auth:SIMPLE))@hdfs://jiahao:9000; URI: hdfs://Jiahao:9000; Object Identity Hash: 1815907a
23/11/10 17:21:19 TRACE FileSystem: FileSystem.close() full stack trace:
java.lang.Throwable
	at org.apache.hadoop.fs.FileSystem.debugLogFileSystemClose(FileSystem.java:645)
	at org.apache.hadoop.fs.FileSystem.close(FileSystem.java:2592)
	at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:1518)
	at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:3678)
	at org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:3695)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
23/11/10 17:21:19 DEBUG Client: stopping client from cache: Client-80ec2482baef42769cda786a84e06274
23/11/10 17:21:19 DEBUG Client: removing client from cache: Client-80ec2482baef42769cda786a84e06274
23/11/10 17:21:19 DEBUG Client: stopping actual client because no more references remain: Client-80ec2482baef42769cda786a84e06274
23/11/10 17:21:19 DEBUG Client: Stopping client
23/11/10 17:21:19 TRACE Client: Interrupted while waiting to retrieve RPC response.
23/11/10 17:21:19 DEBUG Client: IPC Client (1660295258) connection to Jiahao/127.0.1.1:9000 from dbgroup: closed
23/11/10 17:21:19 DEBUG Client: IPC Client (1660295258) connection to Jiahao/127.0.1.1:9000 from dbgroup: stopped, remaining connections 0
23/11/10 17:21:19 DEBUG ShutdownHookManager: Completed shutdown in 0.049 seconds; Timeouts: 0
23/11/10 17:21:19 DEBUG ShutdownHookManager: ShutdownHookManager completed shutdown.
